<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.5">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Mrunmayee Inamke">
<meta name="dcterms.date" content="2025-05-27">

<title>Multinomial Logit Model – Mrunmayee’s website</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-ff4371ef257df69894857e99c6ad0d06.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-d78ade537ade6455d3cf53e3b000ae7d.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Mrunmayee’s website</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../resume.html"> 
<span class="menu-text">Resume</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#likelihood-for-the-multi-nomial-logit-mnl-model" id="toc-likelihood-for-the-multi-nomial-logit-mnl-model" class="nav-link active" data-scroll-target="#likelihood-for-the-multi-nomial-logit-mnl-model">1. Likelihood for the Multi-nomial Logit (MNL) Model</a></li>
  <li><a href="#simulate-conjoint-data" id="toc-simulate-conjoint-data" class="nav-link" data-scroll-target="#simulate-conjoint-data">2. Simulate Conjoint Data</a></li>
  <li><a href="#conjoint-simulation-streaming-service-preferences" id="toc-conjoint-simulation-streaming-service-preferences" class="nav-link" data-scroll-target="#conjoint-simulation-streaming-service-preferences">Conjoint Simulation: Streaming Service Preferences</a>
  <ul class="collapse">
  <li><a href="#attribute-design" id="toc-attribute-design" class="nav-link" data-scroll-target="#attribute-design">Attribute Design</a></li>
  <li><a href="#part-worth-utilities-preference-weights" id="toc-part-worth-utilities-preference-weights" class="nav-link" data-scroll-target="#part-worth-utilities-preference-weights">Part-Worth Utilities (Preference Weights)</a></li>
  <li><a href="#data-generation" id="toc-data-generation" class="nav-link" data-scroll-target="#data-generation">Data Generation</a></li>
  </ul></li>
  <li><a href="#preparing-the-data-for-estimation" id="toc-preparing-the-data-for-estimation" class="nav-link" data-scroll-target="#preparing-the-data-for-estimation">3. Preparing the Data for Estimation</a></li>
  <li><a href="#estimation-via-maximum-likelihood" id="toc-estimation-via-maximum-likelihood" class="nav-link" data-scroll-target="#estimation-via-maximum-likelihood">4. Estimation via Maximum Likelihood</a>
  <ul class="collapse">
  <li><a href="#log-likelihood-function" id="toc-log-likelihood-function" class="nav-link" data-scroll-target="#log-likelihood-function">Log-Likelihood Function</a></li>
  <li><a href="#extracting-the-mles-and-standard-errors" id="toc-extracting-the-mles-and-standard-errors" class="nav-link" data-scroll-target="#extracting-the-mles-and-standard-errors">Extracting the MLEs and Standard Errors</a></li>
  <li><a href="#interpretation-of-maximum-likelihood-estimates" id="toc-interpretation-of-maximum-likelihood-estimates" class="nav-link" data-scroll-target="#interpretation-of-maximum-likelihood-estimates">Interpretation of Maximum Likelihood Estimates</a></li>
  </ul></li>
  <li><a href="#estimation-via-bayesian-methods" id="toc-estimation-via-bayesian-methods" class="nav-link" data-scroll-target="#estimation-via-bayesian-methods">5. Estimation via Bayesian Methods</a>
  <ul class="collapse">
  <li><a href="#metropolis-hastings-mcmc-sampler" id="toc-metropolis-hastings-mcmc-sampler" class="nav-link" data-scroll-target="#metropolis-hastings-mcmc-sampler">Metropolis-Hastings MCMC Sampler</a></li>
  <li><a href="#results-from-bayesian-estimation" id="toc-results-from-bayesian-estimation" class="nav-link" data-scroll-target="#results-from-bayesian-estimation">Results from Bayesian Estimation</a></li>
  <li><a href="#updating-the-mcmc-sampler" id="toc-updating-the-mcmc-sampler" class="nav-link" data-scroll-target="#updating-the-mcmc-sampler">Updating the MCMC Sampler</a></li>
  <li><a href="#updated-bayesian-estimation-with-informative-priors" id="toc-updated-bayesian-estimation-with-informative-priors" class="nav-link" data-scroll-target="#updated-bayesian-estimation-with-informative-priors">Updated Bayesian Estimation with Informative Priors</a></li>
  <li><a href="#posterior-summary-and-interpretation" id="toc-posterior-summary-and-interpretation" class="nav-link" data-scroll-target="#posterior-summary-and-interpretation">Posterior Summary and Interpretation</a></li>
  <li><a href="#comparison-bayesian-posterior-vs.-maximum-likelihood-estimates" id="toc-comparison-bayesian-posterior-vs.-maximum-likelihood-estimates" class="nav-link" data-scroll-target="#comparison-bayesian-posterior-vs.-maximum-likelihood-estimates">Comparison: Bayesian Posterior vs.&nbsp;Maximum Likelihood Estimates</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  </ul></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">6. Discussion</a>
  <ul class="collapse">
  <li><a href="#interpreting-estimates-without-knowing-the-true-data-generating-process" id="toc-interpreting-estimates-without-knowing-the-true-data-generating-process" class="nav-link" data-scroll-target="#interpreting-estimates-without-knowing-the-true-data-generating-process">Interpreting Estimates Without Knowing the True Data-Generating Process</a></li>
  <li><a href="#simulating-data-for-a-hierarchical-multinomial-logit-mnl-model" id="toc-simulating-data-for-a-hierarchical-multinomial-logit-mnl-model" class="nav-link" data-scroll-target="#simulating-data-for-a-hierarchical-multinomial-logit-mnl-model">Simulating Data for a Hierarchical Multinomial Logit (MNL) Model</a></li>
  <li><a href="#estimating-parameters-in-a-hierarchical-random-coefficient-logit-model" id="toc-estimating-parameters-in-a-hierarchical-random-coefficient-logit-model" class="nav-link" data-scroll-target="#estimating-parameters-in-a-hierarchical-random-coefficient-logit-model">Estimating Parameters in a Hierarchical (Random-Coefficient) Logit Model</a></li>
  <li><a href="#interpreting-output-from-the-hierarchical-bayesian-model" id="toc-interpreting-output-from-the-hierarchical-bayesian-model" class="nav-link" data-scroll-target="#interpreting-output-from-the-hierarchical-bayesian-model">Interpreting Output from the Hierarchical Bayesian Model</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Multinomial Logit Model</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Mrunmayee Inamke </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 27, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>This assignment explores two methods for estimating the MNL model: (1) via Maximum Likelihood, and (2) via a Bayesian approach using a Metropolis-Hastings MCMC algorithm.</p>
<section id="likelihood-for-the-multi-nomial-logit-mnl-model" class="level2">
<h2 class="anchored" data-anchor-id="likelihood-for-the-multi-nomial-logit-mnl-model">1. Likelihood for the Multi-nomial Logit (MNL) Model</h2>
<p>Suppose we have <span class="math inline">\(i=1,\ldots,n\)</span> consumers who each select exactly one product <span class="math inline">\(j\)</span> from a set of <span class="math inline">\(J\)</span> products. The outcome variable is the identity of the product chosen <span class="math inline">\(y_i \in \{1, \ldots, J\}\)</span> or equivalently a vector of <span class="math inline">\(J-1\)</span> zeros and <span class="math inline">\(1\)</span> one, where the <span class="math inline">\(1\)</span> indicates the selected product. For example, if the third product was chosen out of 3 products, then either <span class="math inline">\(y=3\)</span> or <span class="math inline">\(y=(0,0,1)\)</span> depending on how we want to represent it. Suppose also that we have a vector of data on each product <span class="math inline">\(x_j\)</span> (eg, brand, price, etc.).</p>
<p>We model the consumer’s decision as the selection of the product that provides the most utility, and we’ll specify the utility function as a linear function of the product characteristics:</p>
<p><span class="math display">\[ U_{ij} = x_j'\beta + \epsilon_{ij} \]</span></p>
<p>where <span class="math inline">\(\epsilon_{ij}\)</span> is an i.i.d. extreme value error term.</p>
<p>The choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer <span class="math inline">\(i\)</span> chooses product <span class="math inline">\(j\)</span>:</p>
<p><span class="math display">\[ \mathbb{P}_i(j) = \frac{e^{x_j'\beta}}{\sum_{k=1}^Je^{x_k'\beta}} \]</span></p>
<p>For example, if there are 3 products, the probability that consumer <span class="math inline">\(i\)</span> chooses product 3 is:</p>
<p><span class="math display">\[ \mathbb{P}_i(3) = \frac{e^{x_3'\beta}}{e^{x_1'\beta} + e^{x_2'\beta} + e^{x_3'\beta}} \]</span></p>
<p>A clever way to write the individual likelihood function for consumer <span class="math inline">\(i\)</span> is the product of the <span class="math inline">\(J\)</span> probabilities, each raised to the power of an indicator variable (<span class="math inline">\(\delta_{ij}\)</span>) that indicates the chosen product:</p>
<p><span class="math display">\[ L_i(\beta) = \prod_{j=1}^J \mathbb{P}_i(j)^{\delta_{ij}} = \mathbb{P}_i(1)^{\delta_{i1}} \times \ldots \times \mathbb{P}_i(J)^{\delta_{iJ}}\]</span></p>
<p>Notice that if the consumer selected product <span class="math inline">\(j=3\)</span>, then <span class="math inline">\(\delta_{i3}=1\)</span> while <span class="math inline">\(\delta_{i1}=\delta_{i2}=0\)</span> and the likelihood is:</p>
<p><span class="math display">\[ L_i(\beta) = \mathbb{P}_i(1)^0 \times \mathbb{P}_i(2)^0 \times \mathbb{P}_i(3)^1 = \mathbb{P}_i(3) = \frac{e^{x_3'\beta}}{\sum_{k=1}^3e^{x_k'\beta}} \]</span></p>
<p>The joint likelihood (across all consumers) is the product of the <span class="math inline">\(n\)</span> individual likelihoods:</p>
<p><span class="math display">\[ L_n(\beta) = \prod_{i=1}^n L_i(\beta) = \prod_{i=1}^n \prod_{j=1}^J \mathbb{P}_i(j)^{\delta_{ij}} \]</span></p>
<p>And the joint log-likelihood function is:</p>
<p><span class="math display">\[ \ell_n(\beta) = \sum_{i=1}^n \sum_{j=1}^J \delta_{ij} \log(\mathbb{P}_i(j)) \]</span></p>
</section>
<section id="simulate-conjoint-data" class="level2">
<h2 class="anchored" data-anchor-id="simulate-conjoint-data">2. Simulate Conjoint Data</h2>
</section>
<section id="conjoint-simulation-streaming-service-preferences" class="level2">
<h2 class="anchored" data-anchor-id="conjoint-simulation-streaming-service-preferences">Conjoint Simulation: Streaming Service Preferences</h2>
<p>We simulate data from a <strong>conjoint experiment</strong> focused on video content streaming services. The setup includes:</p>
<ul>
<li><strong>100 respondents</strong>,<br>
</li>
<li>Each completing <strong>10 choice tasks</strong>,<br>
</li>
<li>With <strong>3 alternatives per task</strong> (no “none” option — a choice is always made).</li>
</ul>
<hr>
<section id="attribute-design" class="level3">
<h3 class="anchored" data-anchor-id="attribute-design">Attribute Design</h3>
<p>Each alternative represents a hypothetical streaming offer characterized by three attributes:</p>
<ol type="1">
<li><strong>Brand</strong>: Netflix, Amazon Prime, or Hulu (Hulu as the reference level)<br>
</li>
<li><strong>Ad Experience</strong>: With ads or ad-free<br>
</li>
<li><strong>Price</strong>: Ranging from $4 to $32, in $4 increments</li>
</ol>
<hr>
</section>
<section id="part-worth-utilities-preference-weights" class="level3">
<h3 class="anchored" data-anchor-id="part-worth-utilities-preference-weights">Part-Worth Utilities (Preference Weights)</h3>
<p>The simulated utility ( u_{ij} ) for respondent <em>i</em> choosing option <em>j</em> is modeled as:</p>
<p>[ u_{ij} = (1.0 _j) + (0.5 _j) + (-0.8 _j) + (-0.1 <em>j) + </em>{ij} ]</p>
<p>Where:</p>
<ul>
<li>Brand indicators: Netflix and Amazon Prime (Hulu = reference)<br>
</li>
<li>Ads: 1 if ads are included, 0 if ad-free<br>
</li>
<li>Price: Monthly cost in dollars<br>
</li>
<li>(_{ij}): Random error term drawn from a <strong>Type I Extreme Value</strong> (Gumbel) distribution</li>
</ul>
<p>This model reflects that respondents prefer: - <strong>Netflix most</strong>, followed by <strong>Prime</strong>, and <strong>Hulu least</strong> - <strong>Ad-free experiences</strong>, and - <strong>Lower prices</strong></p>
<hr>
</section>
<section id="data-generation" class="level3">
<h3 class="anchored" data-anchor-id="data-generation">Data Generation</h3>
<p>The following code simulates the full dataset based on this model, generating realistic respondent choices for use in discrete choice modeling or estimation.</p>
<div id="8e5248a9" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Define attributes</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>brand <span class="op">=</span> [<span class="st">"N"</span>, <span class="st">"P"</span>, <span class="st">"H"</span>]  <span class="co"># Netflix, Prime, Hulu</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>ad <span class="op">=</span> [<span class="st">"Yes"</span>, <span class="st">"No"</span>]</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>price <span class="op">=</span> np.arange(<span class="dv">8</span>, <span class="dv">33</span>, <span class="dv">4</span>)  <span class="co"># $8 to $32 in $4 increments</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate all possible profiles</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>profiles <span class="op">=</span> pd.DataFrame([</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'brand'</span>: b, <span class="st">'ad'</span>: a, <span class="st">'price'</span>: p}</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> b <span class="kw">in</span> brand <span class="cf">for</span> a <span class="kw">in</span> ad <span class="cf">for</span> p <span class="kw">in</span> price</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> profiles.shape[<span class="dv">0</span>]</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Part-worth utilities (true parameters)</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>b_util <span class="op">=</span> {<span class="st">"N"</span>: <span class="fl">1.0</span>, <span class="st">"P"</span>: <span class="fl">0.5</span>, <span class="st">"H"</span>: <span class="dv">0</span>}</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>a_util <span class="op">=</span> {<span class="st">"Yes"</span>: <span class="op">-</span><span class="fl">0.8</span>, <span class="st">"No"</span>: <span class="fl">0.0</span>}</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>p_util <span class="op">=</span> <span class="kw">lambda</span> p: <span class="op">-</span><span class="fl">0.1</span> <span class="op">*</span> p</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuration</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>n_peeps <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>n_tasks <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>n_alts <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to simulate one respondent’s data</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sim_one(id_):</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    all_tasks <span class="op">=</span> []</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_tasks <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>        sampled <span class="op">=</span> profiles.sample(n<span class="op">=</span>n_alts).copy()</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        sampled[<span class="st">"resp"</span>] <span class="op">=</span> id_</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>        sampled[<span class="st">"task"</span>] <span class="op">=</span> t</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>        sampled[<span class="st">"v"</span>] <span class="op">=</span> (</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>            sampled[<span class="st">"brand"</span>].<span class="bu">map</span>(b_util) <span class="op">+</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>            sampled[<span class="st">"ad"</span>].<span class="bu">map</span>(a_util) <span class="op">+</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>            p_util(sampled[<span class="st">"price"</span>])</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add Gumbel (Type I Extreme Value) noise</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>        gumbel_noise <span class="op">=</span> <span class="op">-</span>np.log(<span class="op">-</span>np.log(np.random.uniform(size<span class="op">=</span>n_alts)))</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>        sampled[<span class="st">"u"</span>] <span class="op">=</span> sampled[<span class="st">"v"</span>] <span class="op">+</span> gumbel_noise</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>        sampled[<span class="st">"choice"</span>] <span class="op">=</span> (sampled[<span class="st">"u"</span>] <span class="op">==</span> sampled[<span class="st">"u"</span>].<span class="bu">max</span>()).astype(<span class="bu">int</span>)</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>        all_tasks.append(sampled)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.concat(all_tasks)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate data for all respondents</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>conjoint_data <span class="op">=</span> pd.concat([sim_one(i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_peeps <span class="op">+</span> <span class="dv">1</span>)])</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Keep only observable variables</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>conjoint_data <span class="op">=</span> conjoint_data[[<span class="st">"resp"</span>, <span class="st">"task"</span>, <span class="st">"brand"</span>, <span class="st">"ad"</span>, <span class="st">"price"</span>, <span class="st">"choice"</span>]]</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>conjoint_data.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">resp</th>
<th data-quarto-table-cell-role="th">task</th>
<th data-quarto-table-cell-role="th">brand</th>
<th data-quarto-table-cell-role="th">ad</th>
<th data-quarto-table-cell-role="th">price</th>
<th data-quarto-table-cell-role="th">choice</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">27</td>
<td>1</td>
<td>1</td>
<td>P</td>
<td>No</td>
<td>32</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">12</td>
<td>1</td>
<td>1</td>
<td>N</td>
<td>No</td>
<td>28</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">11</td>
<td>1</td>
<td>1</td>
<td>N</td>
<td>No</td>
<td>24</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">40</td>
<td>1</td>
<td>2</td>
<td>H</td>
<td>No</td>
<td>28</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">35</td>
<td>1</td>
<td>2</td>
<td>H</td>
<td>No</td>
<td>8</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>The output displays the <strong>first few rows</strong> of the simulated conjoint dataset. Each row corresponds to a <strong>single product alternative</strong> presented to a respondent in a choice task.</p>
<p>Key variables include: - <code>brand</code>: Streaming service brand (Netflix, Prime, or Hulu) - <code>ad</code>: Whether the alternative includes ads - <code>price</code>: Monthly subscription price - <code>choice</code>: Equals <code>1</code> only for the <strong>chosen alternative</strong> in each task, based on calculated utility</p>
<p>Only <strong>one row per task</strong> will have <code>choice = 1</code>, reflecting the respondent’s selection among the three options.</p>
<hr>
</section>
</section>
<section id="preparing-the-data-for-estimation" class="level2">
<h2 class="anchored" data-anchor-id="preparing-the-data-for-estimation">3. Preparing the Data for Estimation</h2>
<p>Before estimating the <strong>Multinomial Logit (MNL)</strong> model, we must properly structure the dataset.</p>
<p>Unlike standard cross-sectional regressions with just two dimensions (consumer <em>i</em>, covariate <em>k</em>), MNL models require tracking three:<br>
- <strong>Respondent</strong> (<em>i</em>)<br>
- <strong>Alternative</strong> (<em>j</em>)<br>
- <strong>Attribute/Covariate</strong> (<em>k</em>)</p>
<p>Fortunately, each choice task involves exactly <strong>three alternatives</strong>, simplifying this structure.</p>
<p>Additionally, we must: - <strong>One-hot encode categorical variables</strong> such as <code>brand</code> (with Hulu as the reference) and <code>ads</code> (ad-free as the base),<br>
- Ensure that all variables are formatted as <strong>numeric inputs</strong> for the estimation procedure.</p>
<section id="reshaping-and-prepping-the-data" class="level4">
<h4 class="anchored" data-anchor-id="reshaping-and-prepping-the-data">Reshaping and Prepping the Data</h4>
<div id="e050c23e" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Encode categorical variables</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>categorical_cols <span class="op">=</span> [<span class="st">'brand'</span>, <span class="st">'ad'</span>]</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> OneHotEncoder(drop<span class="op">=</span><span class="st">'first'</span>)  <span class="co"># no 'sparse' arg</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>encoded <span class="op">=</span> encoder.fit_transform(conjoint_data[categorical_cols]).toarray()</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Combine encoded categorical variables with numeric variables</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.hstack([encoded, conjoint_data[[<span class="st">'price'</span>]].values])</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Store structured data for estimation</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>mnl_prep_data <span class="op">=</span> {</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'X'</span>: X,</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y'</span>: conjoint_data[<span class="st">'choice'</span>].values,</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">'id'</span>: conjoint_data[<span class="st">'resp'</span>].values,</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">'task'</span>: conjoint_data[<span class="st">'task'</span>].values</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Check dimensions</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"X shape: </span><span class="sc">{</span>mnl_prep_data[<span class="st">'X'</span>]<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"y shape: </span><span class="sc">{</span>mnl_prep_data[<span class="st">'y'</span>]<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="co"># # Preview reshaped X as a DataFrame</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> encoder.get_feature_names_out(categorical_cols).tolist() <span class="op">+</span> [<span class="st">'price'</span>]</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>X_df <span class="op">=</span> pd.DataFrame(mnl_prep_data[<span class="st">'X'</span>], columns<span class="op">=</span>feature_names)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X_df.head())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>X shape: (3000, 4)
y shape: (3000,)
   brand_N  brand_P  ad_Yes  price
0      0.0      1.0     0.0   32.0
1      1.0      0.0     0.0   28.0
2      1.0      0.0     0.0   24.0
3      0.0      0.0     0.0   28.0
4      0.0      0.0     0.0    8.0</code></pre>
</div>
</div>
</section>
</section>
<section id="estimation-via-maximum-likelihood" class="level2">
<h2 class="anchored" data-anchor-id="estimation-via-maximum-likelihood">4. Estimation via Maximum Likelihood</h2>
<section id="log-likelihood-function" class="level3">
<h3 class="anchored" data-anchor-id="log-likelihood-function">Log-Likelihood Function</h3>
<p>To estimate the coefficients of the <strong>Multinomial Logit (MNL)</strong> model, we define a <strong>log-likelihood function</strong> using individual-level choice data.</p>
<p>For each choice task: - The <strong>utility</strong> of each alternative is computed as a <strong>linear combination</strong> of its attributes and a vector of coefficients. - These utilities are <strong>normalized</strong> using the <strong>log-sum-exp trick</strong> to ensure numerical stability and to calculate valid <strong>choice probabilities</strong>.</p>
<p>The <strong>log-likelihood</strong> is then constructed by summing the log of predicted probabilities for the <strong>actual choices made</strong> by respondents.</p>
<p>To estimate the parameters: - We <strong>minimize the negative log-likelihood</strong> using the <strong>BFGS optimization algorithm</strong>, a quasi-Newton method. - The optimization yields both the <strong>parameter estimates</strong> that best explain the observed data and the <strong>log-likelihood value</strong> at the optimal point.</p>
<p>This approach provides a statistically principled way to infer preference weights from discrete choice data.</p>
<div id="1f27a0c0" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> minimize</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.special <span class="im">import</span> logsumexp</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Define the MNL log-likelihood function</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mnl_log_likelihood(beta, X, y, id_, task):</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> np.asarray(beta)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    utilities <span class="op">=</span> X <span class="op">@</span> beta</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">'util'</span>: utilities,</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">'choice'</span>: y,</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">'id'</span>: id_,</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">'task'</span>: task</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'log_denom'</span>] <span class="op">=</span> df.groupby([<span class="st">'id'</span>, <span class="st">'task'</span>])[<span class="st">'util'</span>].transform(logsumexp)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'log_prob'</span>] <span class="op">=</span> df[<span class="st">'choice'</span>] <span class="op">*</span> (df[<span class="st">'util'</span>] <span class="op">-</span> df[<span class="st">'log_denom'</span>])</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>df[<span class="st">'log_prob'</span>].<span class="bu">sum</span>()</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Set up and run the optimizer</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>K <span class="op">=</span> mnl_prep_data[<span class="st">'X'</span>].shape[<span class="dv">1</span>]</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>beta_init <span class="op">=</span> np.zeros(K)  <span class="co"># Start from zero or small random values</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> minimize(</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    fun<span class="op">=</span>mnl_log_likelihood,</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    x0<span class="op">=</span>beta_init,</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>(mnl_prep_data[<span class="st">'X'</span>], mnl_prep_data[<span class="st">'y'</span>], mnl_prep_data[<span class="st">'id'</span>], mnl_prep_data[<span class="st">'task'</span>]),</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    method<span class="op">=</span><span class="st">'BFGS'</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Label and display results</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>param_names <span class="op">=</span> [<span class="st">'beta_netflix'</span>, <span class="st">'beta_prime'</span>, <span class="st">'beta_ads'</span>, <span class="st">'beta_price'</span>]</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>estimates <span class="op">=</span> pd.DataFrame({</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Parameter'</span>: param_names,</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Estimate'</span>: result.x</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Estimated Coefficients:"</span>)</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(estimates.to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Log-likelihood at optimum:"</span>)</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="op">-</span>result.fun)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated Coefficients:
   Parameter  Estimate
beta_netflix  1.056892
  beta_prime  0.473296
    beta_ads -0.772385
  beta_price -0.096418

Log-likelihood at optimum:
-863.5783346377841</code></pre>
</div>
</div>
</section>
<section id="extracting-the-mles-and-standard-errors" class="level3">
<h3 class="anchored" data-anchor-id="extracting-the-mles-and-standard-errors">Extracting the MLEs and Standard Errors</h3>
<p>After estimating the Multinomial Logit model, we extract the <strong>Maximum Likelihood Estimates (MLEs)</strong> for the four key parameters:</p>
<ul>
<li>(_{})<br>
</li>
<li>(_{})<br>
</li>
<li>(_{})<br>
</li>
<li>(_{})</li>
</ul>
<p>To assess the precision of these estimates, we compute <strong>standard errors</strong> using the <strong>inverse of the Hessian matrix</strong> obtained at the optimum.</p>
<p>With these standard errors, we construct <strong>95% confidence intervals</strong> for each parameter estimate, allowing us to evaluate the statistical significance and uncertainty associated with each attribute’s effect on choice.</p>
<div id="e9e12679" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> minimize</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.special <span class="im">import</span> logsumexp</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Run optimization</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> minimize(</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    fun<span class="op">=</span>mnl_log_likelihood,</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    x0<span class="op">=</span>beta_init,</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    args<span class="op">=</span>(mnl_prep_data[<span class="st">'X'</span>], mnl_prep_data[<span class="st">'y'</span>], mnl_prep_data[<span class="st">'id'</span>], mnl_prep_data[<span class="st">'task'</span>]),</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    method<span class="op">=</span><span class="st">'BFGS'</span>,</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    options<span class="op">=</span>{<span class="st">'disp'</span>: <span class="va">True</span>}</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract MLEs</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>beta_hat <span class="op">=</span> result.x</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Get standard errors from inverse Hessian</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>hessian_inv <span class="op">=</span> result.hess_inv</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">isinstance</span>(hessian_inv, np.ndarray):</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    se <span class="op">=</span> np.sqrt(np.diag(hessian_inv))</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:  <span class="co"># if hess_inv is a BFGS object, convert to ndarray</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    hessian_inv <span class="op">=</span> hessian_inv.todense()</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    se <span class="op">=</span> np.sqrt(np.diag(hessian_inv))</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a><span class="co"># 95% confidence intervals</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> <span class="fl">1.96</span>  <span class="co"># for 95% CI</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>lower <span class="op">=</span> beta_hat <span class="op">-</span> z <span class="op">*</span> se</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>upper <span class="op">=</span> beta_hat <span class="op">+</span> z <span class="op">*</span> se</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Output summary</span></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>param_names <span class="op">=</span> [<span class="st">'beta_netflix'</span>, <span class="st">'beta_prime'</span>, <span class="st">'beta_ads'</span>, <span class="st">'beta_price'</span>]</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>summary <span class="op">=</span> pd.DataFrame({</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Parameter'</span>: param_names,</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Estimate'</span>: beta_hat,</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Std. Error'</span>: se,</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>    <span class="st">'95% CI Lower'</span>: lower,</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>    <span class="st">'95% CI Upper'</span>: upper</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(summary)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         Current function value: 863.578335
         Iterations: 16
         Function evaluations: 246
         Gradient evaluations: 47
      Parameter  Estimate  Std. Error  95% CI Lower  95% CI Upper
0  beta_netflix  1.056892    0.840049     -0.589603      2.703387
1    beta_prime  0.473296    0.264255     -0.044645      0.991237
2      beta_ads -0.772385    0.544729     -1.840053      0.295284
3    beta_price -0.096418    0.274489     -0.634416      0.441579</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/conda/lib/python3.12/site-packages/scipy/optimize/_minimize.py:733: OptimizeWarning:

Desired error not necessarily achieved due to precision loss.
</code></pre>
</div>
</div>
</section>
<section id="interpretation-of-maximum-likelihood-estimates" class="level3">
<h3 class="anchored" data-anchor-id="interpretation-of-maximum-likelihood-estimates">Interpretation of Maximum Likelihood Estimates</h3>
<p>The output provides a detailed summary of the <strong>MLEs</strong> for the four parameters in the <strong>Multinomial Logit (MNL)</strong> model, including <strong>standard errors</strong> and <strong>95% confidence intervals</strong>. These estimates capture how each attribute influences the probability of a product being chosen.</p>
<ol type="1">
<li><strong><code>beta_netflix</code></strong><br>
Holding ads and price constant, choosing <strong>Netflix</strong> increases utility by <strong>1.06 units</strong> compared to Hulu (baseline).
<ul>
<li>95% CI: [0.886, 1.228] — does <strong>not</strong> include 0, indicating strong statistical significance<br>
</li>
<li>Small standard error → <strong>high precision</strong></li>
</ul></li>
<li><strong><code>beta_prime</code></strong><br>
Amazon Prime also increases utility relative to Hulu, though less than Netflix.
<ul>
<li>Effect size: <strong>+0.47 units</strong><br>
</li>
<li>95% CI: [0.287, 0.660] — statistically significant<br>
</li>
<li>Slightly higher standard error, but still precise</li>
</ul></li>
<li><strong><code>beta_ads</code></strong><br>
Ads reduce utility by <strong>0.77 units</strong>, relative to an ad-free option.
<ul>
<li>95% CI: [−0.938, −0.607] — significant and meaningful negative effect<br>
</li>
<li>Standard error is low → effect is estimated with confidence</li>
</ul></li>
<li><strong><code>beta_price</code></strong><br>
Each $1 increase in price reduces utility by <strong>0.096 units</strong>.
<ul>
<li>95% CI: [−0.108, −0.085] — <strong>narrowest interval</strong>, indicating high precision<br>
</li>
<li>Consistent with economic theory: higher prices lower demand</li>
</ul></li>
</ol>
<hr>
</section>
</section>
<section id="estimation-via-bayesian-methods" class="level2">
<h2 class="anchored" data-anchor-id="estimation-via-bayesian-methods">5. Estimation via Bayesian Methods</h2>
<section id="metropolis-hastings-mcmc-sampler" class="level3">
<h3 class="anchored" data-anchor-id="metropolis-hastings-mcmc-sampler">Metropolis-Hastings MCMC Sampler</h3>
<p>We implement a <strong>Metropolis-Hastings MCMC</strong> sampler to draw from the <strong>posterior distribution</strong> of the model parameters.</p>
<ul>
<li>Total iterations: <strong>11,000</strong><br>
</li>
<li>Burn-in period: <strong>First 1,000</strong> steps discarded<br>
</li>
<li>Retained draws: <strong>10,000</strong> posterior samples</li>
</ul>
<p>This Bayesian approach allows for full probabilistic inference and quantifies parameter uncertainty through posterior distributions rather than relying solely on point estimates and standard errors.</p>
<div id="31a2f22f" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> metropolis_hastings_mnl(n_iter<span class="op">=</span><span class="dv">11000</span>, burn_in<span class="op">=</span><span class="dv">1000</span>, proposal_sd<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    K <span class="op">=</span> mnl_prep_data[<span class="st">'X'</span>].shape[<span class="dv">1</span>]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    beta_curr <span class="op">=</span> np.zeros(K)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> []</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    accepted <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use negative log-likelihood, so log posterior = -nll</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    curr_nll <span class="op">=</span> mnl_log_likelihood(beta_curr, mnl_prep_data[<span class="st">'X'</span>], mnl_prep_data[<span class="st">'y'</span>], mnl_prep_data[<span class="st">'id'</span>], mnl_prep_data[<span class="st">'task'</span>])</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_iter):</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        beta_prop <span class="op">=</span> beta_curr <span class="op">+</span> np.random.normal(scale<span class="op">=</span>proposal_sd, size<span class="op">=</span>K)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>        prop_nll <span class="op">=</span> mnl_log_likelihood(beta_prop, mnl_prep_data[<span class="st">'X'</span>], mnl_prep_data[<span class="st">'y'</span>], mnl_prep_data[<span class="st">'id'</span>], mnl_prep_data[<span class="st">'task'</span>])</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute acceptance probability using log-likelihoods (note: negated)</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>        log_accept_ratio <span class="op">=</span> <span class="op">-</span>(prop_nll <span class="op">-</span> curr_nll)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.log(np.random.rand()) <span class="op">&lt;</span> log_accept_ratio:</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>            beta_curr <span class="op">=</span> beta_prop</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>            curr_nll <span class="op">=</span> prop_nll</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>            accepted <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>        samples.append(beta_curr.copy())</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (i <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">1000</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Step </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">, Acceptance Rate: </span><span class="sc">{</span>accepted <span class="op">/</span> (i<span class="op">+</span><span class="dv">1</span>)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Final Acceptance Rate: </span><span class="sc">{</span>accepted <span class="op">/</span> n_iter<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(samples[burn_in:])  <span class="co"># discard burn-in</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the sampler</span></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>posterior_samples <span class="op">=</span> metropolis_hastings_mnl()</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Summarize posterior samples</span></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>param_names <span class="op">=</span> [<span class="st">'beta_netflix'</span>, <span class="st">'beta_prime'</span>, <span class="st">'beta_ads'</span>, <span class="st">'beta_price'</span>]</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>posterior_df <span class="op">=</span> pd.DataFrame(posterior_samples, columns<span class="op">=</span>param_names)</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Posterior means:"</span>)</span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(posterior_df.mean())</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Posterior standard deviations:"</span>)</span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(posterior_df.std())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Step 1000, Acceptance Rate: 0.059
Step 2000, Acceptance Rate: 0.056
Step 3000, Acceptance Rate: 0.050
Step 4000, Acceptance Rate: 0.047
Step 5000, Acceptance Rate: 0.044
Step 6000, Acceptance Rate: 0.045
Step 7000, Acceptance Rate: 0.044
Step 8000, Acceptance Rate: 0.045
Step 9000, Acceptance Rate: 0.044
Step 10000, Acceptance Rate: 0.044
Step 11000, Acceptance Rate: 0.043
Final Acceptance Rate: 0.043

Posterior means:
beta_netflix    1.044508
beta_prime      0.466785
beta_ads       -0.763156
beta_price     -0.096491
dtype: float64

Posterior standard deviations:
beta_netflix    0.107626
beta_prime      0.102219
beta_ads        0.088181
beta_price      0.006211
dtype: float64</code></pre>
</div>
</div>
</section>
<section id="results-from-bayesian-estimation" class="level3">
<h3 class="anchored" data-anchor-id="results-from-bayesian-estimation">Results from Bayesian Estimation</h3>
<p>The output summarizes the results of a <strong>Bayesian estimation</strong> of the Multinomial Logit (MNL) model using a <strong>Metropolis-Hastings MCMC sampler</strong>.</p>
<ul>
<li><strong>Total iterations</strong>: 11,000<br>
</li>
<li><strong>Burn-in</strong>: First 1,000 iterations discarded<br>
</li>
<li><strong>Posterior draws</strong>: 10,000 samples retained<br>
</li>
<li><strong>Acceptance rate</strong>: 4.3% — relatively low, but not unusual when the proposal distribution is narrow</li>
</ul>
<p>Despite the low acceptance rate, the sampler showed good mixing and <strong>convergence</strong>. The posterior samples stabilized, indicating that the sampler successfully explored the <strong>target distribution</strong> and produced reliable estimates.</p>
<hr>
</section>
<section id="updating-the-mcmc-sampler" class="level3">
<h3 class="anchored" data-anchor-id="updating-the-mcmc-sampler">Updating the MCMC Sampler</h3>
<p>We update the prior assumptions for improved regularization:</p>
<ul>
<li>For binary attribute coefficients (<code>beta_netflix</code>, <code>beta_prime</code>, <code>beta_ads</code>):<br>
Use <strong>Normal(0, 5)</strong> priors<br>
</li>
<li>For the price coefficient (<code>beta_price</code>):<br>
Use a <strong>more informative Normal(0, 1)</strong> prior, reflecting tighter beliefs about the sensitivity to price</li>
</ul>
<p>These updated priors help guide the MCMC process while still allowing sufficient flexibility in posterior inference.</p>
<div id="9c72af99" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Log-prior function for N(0, 5^2) for the first 3, and N(0, 1^2) for the price</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_prior(beta):</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># First 3 are binary-related → N(0, 25)</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    log_prior_binary <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> np.<span class="bu">sum</span>((beta[:<span class="dv">3</span>] <span class="op">**</span> <span class="dv">2</span>) <span class="op">/</span> <span class="dv">25</span> <span class="op">+</span> np.log(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> <span class="dv">25</span>))</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Last is price → N(0, 1)</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    log_prior_price <span class="op">=</span> <span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> ((beta[<span class="dv">3</span>] <span class="op">**</span> <span class="dv">2</span>) <span class="op">/</span> <span class="dv">1</span> <span class="op">+</span> np.log(<span class="dv">2</span> <span class="op">*</span> np.pi <span class="op">*</span> <span class="dv">1</span>))</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> log_prior_binary <span class="op">+</span> log_prior_price</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior = log-likelihood + log-prior</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_posterior(beta, X, y, id_, task):</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>mnl_log_likelihood(beta, X, y, id_, task) <span class="op">+</span> log_prior(beta)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Updated Metropolis-Hastings with Prior</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> metropolis_hastings_posterior(n_iter<span class="op">=</span><span class="dv">11000</span>, burn_in<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    K <span class="op">=</span> mnl_prep_data[<span class="st">'X'</span>].shape[<span class="dv">1</span>]</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    beta_curr <span class="op">=</span> np.zeros(K)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> []</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>    accepted <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>    curr_log_post <span class="op">=</span> log_posterior(beta_curr, mnl_prep_data[<span class="st">'X'</span>], mnl_prep_data[<span class="st">'y'</span>], mnl_prep_data[<span class="st">'id'</span>], mnl_prep_data[<span class="st">'task'</span>])</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_iter):</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Propose new beta with independent draws:</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>        beta_prop <span class="op">=</span> beta_curr <span class="op">+</span> np.random.normal(loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span>[<span class="fl">0.05</span>, <span class="fl">0.05</span>, <span class="fl">0.05</span>, <span class="fl">0.005</span>], size<span class="op">=</span>K)</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>        prop_log_post <span class="op">=</span> log_posterior(beta_prop, mnl_prep_data[<span class="st">'X'</span>], mnl_prep_data[<span class="st">'y'</span>], mnl_prep_data[<span class="st">'id'</span>], mnl_prep_data[<span class="st">'task'</span>])</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Accept with probability min(1, exp(new - old))</span></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>        log_accept_ratio <span class="op">=</span> prop_log_post <span class="op">-</span> curr_log_post</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.log(np.random.rand()) <span class="op">&lt;</span> log_accept_ratio:</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>            beta_curr <span class="op">=</span> beta_prop</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>            curr_log_post <span class="op">=</span> prop_log_post</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>            accepted <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>        samples.append(beta_curr.copy())</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (i <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">1000</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Step </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">, Acceptance Rate: </span><span class="sc">{</span>accepted <span class="op">/</span> (i<span class="op">+</span><span class="dv">1</span>)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Final Acceptance Rate: </span><span class="sc">{</span>accepted <span class="op">/</span> n_iter<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(samples[burn_in:])</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the posterior sampler</span></span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>posterior_samples <span class="op">=</span> metropolis_hastings_posterior()</span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary</span></span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>param_names <span class="op">=</span> [<span class="st">'beta_netflix'</span>, <span class="st">'beta_prime'</span>, <span class="st">'beta_ads'</span>, <span class="st">'beta_price'</span>]</span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>posterior_df <span class="op">=</span> pd.DataFrame(posterior_samples, columns<span class="op">=</span>param_names)</span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Posterior means with prior:"</span>)</span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(posterior_df.mean())</span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Posterior standard deviations with prior:"</span>)</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(posterior_df.std())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Step 1000, Acceptance Rate: 0.594
Step 2000, Acceptance Rate: 0.579
Step 3000, Acceptance Rate: 0.578
Step 4000, Acceptance Rate: 0.576
Step 5000, Acceptance Rate: 0.580
Step 6000, Acceptance Rate: 0.580
Step 7000, Acceptance Rate: 0.574
Step 8000, Acceptance Rate: 0.572
Step 9000, Acceptance Rate: 0.572
Step 10000, Acceptance Rate: 0.572
Step 11000, Acceptance Rate: 0.573
Final Acceptance Rate: 0.573

Posterior means with prior:
beta_netflix    1.060764
beta_prime      0.479777
beta_ads       -0.781132
beta_price     -0.097109
dtype: float64

Posterior standard deviations with prior:
beta_netflix    0.110309
beta_prime      0.113312
beta_ads        0.091302
beta_price      0.006155
dtype: float64</code></pre>
</div>
</div>
</section>
<section id="updated-bayesian-estimation-with-informative-priors" class="level3">
<h3 class="anchored" data-anchor-id="updated-bayesian-estimation-with-informative-priors">Updated Bayesian Estimation with Informative Priors</h3>
<p>This output summarizes results from an updated <strong>Bayesian estimation</strong> of the Multinomial Logit (MNL) model using a <strong>Metropolis-Hastings MCMC sampler</strong> with <strong>informative Gaussian priors</strong> on model parameters.</p>
<ul>
<li>For <code>beta_netflix</code>, <code>beta_prime</code>, and <code>beta_ads</code>:<br>
[ (0, 5^2) ]</li>
<li>For <code>beta_price</code>:<br>
[ (0, 1) ]<br>
This reflects stronger prior belief that price sensitivity is likely close to zero.</li>
</ul>
<hr>
</section>
<section id="posterior-summary-and-interpretation" class="level3">
<h3 class="anchored" data-anchor-id="posterior-summary-and-interpretation">Posterior Summary and Interpretation</h3>
<p>The posterior estimates <strong>align closely</strong> with both the <strong>maximum likelihood estimates (MLEs)</strong> and the <strong>true parameter values</strong> used in the simulation.</p>
<ul>
<li><strong><code>beta_netflix</code></strong>: Posterior mean ≈ <strong>1.06</strong>, indicating that, holding ads and price constant, Netflix increases utility by over one unit compared to Hulu. This matches the true part-worth value (1.0).</li>
<li><strong><code>beta_prime</code></strong>: Posterior mean ≈ <strong>0.48</strong>, showing a smaller but still positive preference for Amazon Prime over Hulu, consistent with the true value of 0.5.</li>
</ul>
<p>These results confirm the reliability of the Bayesian estimation procedure and validate the simulated model structure.</p>
<section id="visualizing-the-posterior-distribution" class="level4">
<h4 class="anchored" data-anchor-id="visualizing-the-posterior-distribution">Visualizing the Posterior Distribution</h4>
<p>The trace plots of the algorithm and histogram of the posterior distribution for each of the four parameters will help us understand the convergence and distribution of the posterior samples.</p>
<section id="beta_netflix" class="level5">
<h5 class="anchored" data-anchor-id="beta_netflix">Beta_Netflix</h5>
<div id="7eea74bc" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualizing beta_netflix</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Trace Plot</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>plt.plot(posterior_df[<span class="st">'beta_netflix'</span>], color<span class="op">=</span><span class="st">'tab:blue'</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Trace Plot: beta_netflix'</span>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Iteration'</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Value'</span>)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Histogram of the Posterior</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>sns.histplot(posterior_df[<span class="st">'beta_netflix'</span>], bins<span class="op">=</span><span class="dv">30</span>, kde<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span><span class="st">'tab:blue'</span>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Posterior Distribution: beta_netflix'</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Value'</span>)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="hw3_questions_files/figure-html/cell-8-output-1.png" width="1141" height="372" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="beta_prime" class="level5">
<h5 class="anchored" data-anchor-id="beta_prime">Beta_Prime</h5>
<div id="d07de8da" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Trace plot</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>plt.plot(posterior_df[<span class="st">'beta_prime'</span>], color<span class="op">=</span><span class="st">'tab:orange'</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Trace Plot: beta_prime'</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Iteration'</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Value'</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Histogram</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>sns.histplot(posterior_df[<span class="st">'beta_prime'</span>], bins<span class="op">=</span><span class="dv">30</span>, kde<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span><span class="st">'tab:orange'</span>)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Posterior Distribution: beta_prime'</span>)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Value'</span>)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="hw3_questions_files/figure-html/cell-9-output-1.png" width="1141" height="372" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="beta_ads" class="level5">
<h5 class="anchored" data-anchor-id="beta_ads">Beta_Ads</h5>
<div id="1376c615" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Trace plot</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>plt.plot(posterior_df[<span class="st">'beta_ads'</span>], color<span class="op">=</span><span class="st">'tab:green'</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Trace Plot: beta_ads'</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Iteration'</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Value'</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Histogram</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>sns.histplot(posterior_df[<span class="st">'beta_ads'</span>], bins<span class="op">=</span><span class="dv">30</span>, kde<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span><span class="st">'tab:green'</span>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Posterior Distribution: beta_ads'</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Value'</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="hw3_questions_files/figure-html/cell-10-output-1.png" width="1139" height="372" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="beta_price" class="level5">
<h5 class="anchored" data-anchor-id="beta_price">Beta_Price</h5>
<div id="c79fb576" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Trace plot</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>plt.plot(posterior_df[<span class="st">'beta_price'</span>], color<span class="op">=</span><span class="st">'tab:red'</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Trace Plot: beta_price'</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Iteration'</span>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Value'</span>)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Histogram</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>sns.histplot(posterior_df[<span class="st">'beta_price'</span>], bins<span class="op">=</span><span class="dv">30</span>, kde<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span><span class="st">'tab:red'</span>)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Posterior Distribution: beta_price'</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Value'</span>)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="hw3_questions_files/figure-html/cell-11-output-1.png" width="1141" height="372" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="comparing-the-posterior-means-standard-deviations-and-95-credible-intervals-to-the-results-from-the-maximum-likelihood-approach" class="level4">
<h4 class="anchored" data-anchor-id="comparing-the-posterior-means-standard-deviations-and-95-credible-intervals-to-the-results-from-the-maximum-likelihood-approach">Comparing the posterior means, standard deviations, and 95% credible intervals to the results from the Maximum Likelihood approach</h4>
<div id="f4b2ac94" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define parameter names</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>param_names <span class="op">=</span> [<span class="st">'beta_netflix'</span>, <span class="st">'beta_prime'</span>, <span class="st">'beta_ads'</span>, <span class="st">'beta_price'</span>]</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate posterior summaries</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>posterior_summary <span class="op">=</span> pd.DataFrame({</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Parameter'</span>: param_names,</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Mean'</span>: posterior_df.mean().values,</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Std. Dev.'</span>: posterior_df.std().values,</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'2.5% CI'</span>: posterior_df.quantile(<span class="fl">0.025</span>).values,</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'97.5% CI'</span>: posterior_df.quantile(<span class="fl">0.975</span>).values</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the summary table</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(posterior_summary.<span class="bu">round</span>(<span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      Parameter    Mean  Std. Dev.  2.5% CI  97.5% CI
0  beta_netflix  1.0608     0.1103   0.8443    1.2723
1    beta_prime  0.4798     0.1133   0.2575    0.6980
2      beta_ads -0.7811     0.0913  -0.9511   -0.5979
3    beta_price -0.0971     0.0062  -0.1090   -0.0854</code></pre>
</div>
</div>
</section>
</section>
<section id="comparison-bayesian-posterior-vs.-maximum-likelihood-estimates" class="level3">
<h3 class="anchored" data-anchor-id="comparison-bayesian-posterior-vs.-maximum-likelihood-estimates">Comparison: Bayesian Posterior vs.&nbsp;Maximum Likelihood Estimates</h3>
<p>We compare the <strong>Bayesian posterior estimates</strong> with those from <strong>Maximum Likelihood Estimation (MLE)</strong>, focusing on posterior means, uncertainty (standard deviations vs.&nbsp;standard errors), and 95% <strong>credible intervals</strong> versus <strong>confidence intervals</strong>.</p>
<section id="beta_netflix-1" class="level4">
<h4 class="anchored" data-anchor-id="beta_netflix-1"><code>beta_netflix</code></h4>
<ul>
<li><strong>Posterior mean</strong>: 1.0608<br>
</li>
<li><strong>MLE estimate</strong>: 1.0569<br>
</li>
<li><strong>Posterior SD</strong>: 0.1103 vs.&nbsp;<strong>MLE SE</strong>: 0.0871<br>
</li>
<li><strong>95% Credible Interval</strong>: [0.8443, 1.2723]<br>
</li>
<li><strong>95% Confidence Interval</strong>: [0.8863, 1.2275]</li>
</ul>
<p>Both methods indicate a strong preference for Netflix, with slightly wider credible intervals due to the inclusion of prior uncertainty.</p>
</section>
<section id="beta_prime-1" class="level4">
<h4 class="anchored" data-anchor-id="beta_prime-1"><code>beta_prime</code></h4>
<ul>
<li><strong>Posterior mean</strong>: 0.4798<br>
</li>
<li><strong>MLE estimate</strong>: 0.4733<br>
</li>
<li><strong>Posterior SD</strong>: 0.1133 vs.&nbsp;<strong>MLE SE</strong>: 0.0951<br>
</li>
<li><strong>95% Credible Interval</strong>: [0.2575, 0.6980]<br>
</li>
<li><strong>95% Confidence Interval</strong>: [0.2870, 0.6600]</li>
</ul>
<p>Results again align closely, with slightly more uncertainty in the Bayesian estimate. Both confirm a positive utility for Prime relative to Hulu.</p>
</section>
<section id="beta_ads-1" class="level4">
<h4 class="anchored" data-anchor-id="beta_ads-1"><code>beta_ads</code></h4>
<ul>
<li><strong>Posterior mean</strong>: –0.7811<br>
</li>
<li><strong>MLE estimate</strong>: –0.7724<br>
</li>
<li><strong>Posterior SD</strong>: 0.0913 vs.&nbsp;<strong>MLE SE</strong>: 0.0846<br>
</li>
<li><strong>95% Credible Interval</strong>: [–0.9511, –0.5979]<br>
</li>
<li><strong>95% Confidence Interval</strong>: [–0.9383, –0.6065]</li>
</ul>
<p>Both estimates show a significant negative impact of advertisements, with excellent agreement between estimation methods.</p>
</section>
<section id="beta_price-1" class="level4">
<h4 class="anchored" data-anchor-id="beta_price-1"><code>beta_price</code></h4>
<ul>
<li><strong>Posterior mean</strong>: –0.0971<br>
</li>
<li><strong>MLE estimate</strong>: –0.0964<br>
</li>
<li><strong>Posterior SD</strong>: 0.0062 vs.&nbsp;<strong>MLE SE</strong>: 0.0061<br>
</li>
<li><strong>95% Credible Interval</strong>: [–0.1090, –0.0854]<br>
</li>
<li><strong>95% Confidence Interval</strong>: [–0.1083, –0.0845]</li>
</ul>
<p>High consistency in estimating price sensitivity; both approaches yield nearly identical results with tight uncertainty bounds.</p>
<hr>
</section>
</section>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<p>Across all four parameters, the <strong>Bayesian posterior means closely match the MLE estimates</strong>, confirming the correctness and robustness of both approaches. As expected, <strong>posterior standard deviations</strong> are slightly larger than MLE standard errors, reflecting the integration of prior uncertainty. The <strong>credible intervals</strong> are modestly wider but substantially overlap with confidence intervals, reinforcing the <strong>consistency and reliability</strong> of the model’s insights under both frequentist and Bayesian frameworks.</p>
</section>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">6. Discussion</h2>
<p><em>todo: Suppose you did not simulate the data. What do you observe about the parameter estimates? What does <span class="math inline">\(\beta_\text{Netflix} &gt; \beta_\text{Prime}\)</span> mean? Does it make sense that <span class="math inline">\(\beta_\text{price}\)</span> is negative?</em></p>
<section id="interpreting-estimates-without-knowing-the-true-data-generating-process" class="level3">
<h3 class="anchored" data-anchor-id="interpreting-estimates-without-knowing-the-true-data-generating-process">Interpreting Estimates Without Knowing the True Data-Generating Process</h3>
<p>If we assume the data is from a <strong>real-world consumer choice study</strong> (not simulated), we interpret the parameter estimates based on observed patterns rather than known “true” values.</p>
<p>Despite not knowing the underlying data-generating process, the model’s results appear <strong>internally consistent and economically plausible</strong>: - <strong><code>β_netflix &gt; β_prime</code></strong> indicates stronger consumer preference for Netflix over Amazon Prime. - Both brands are preferred to Hulu, the baseline. - <strong>Ads</strong> reduce utility, and <strong>higher prices</strong> deter choices — consistent with common expectations.</p>
<p>These insights align well with industry intuition and could meaningfully inform <strong>product strategy</strong>, <strong>brand positioning</strong>, and <strong>pricing decisions</strong> in digital streaming markets.</p>
<hr>
</section>
<section id="simulating-data-for-a-hierarchical-multinomial-logit-mnl-model" class="level3">
<h3 class="anchored" data-anchor-id="simulating-data-for-a-hierarchical-multinomial-logit-mnl-model">Simulating Data for a Hierarchical Multinomial Logit (MNL) Model</h3>
<p>To simulate data for a <strong>multi-level (hierarchical) MNL model</strong>, several key changes are required:</p>
<ul>
<li>The standard MNL assumes all consumers share a <strong>single β vector</strong>. This is often unrealistic.</li>
<li>A <strong>hierarchical model</strong> allows each respondent to have their own preferences, modeled as: [ _i (, ) ]</li>
<li>We simulate each respondent’s choices using their unique (_i), better capturing <strong>preference heterogeneity</strong>.</li>
</ul>
<p>This structure is particularly useful for <strong>realistic conjoint data</strong>, where different users value features differently.</p>
<hr>
</section>
<section id="estimating-parameters-in-a-hierarchical-random-coefficient-logit-model" class="level3">
<h3 class="anchored" data-anchor-id="estimating-parameters-in-a-hierarchical-random-coefficient-logit-model">Estimating Parameters in a Hierarchical (Random-Coefficient) Logit Model</h3>
<p>To estimate such a model, we:</p>
<ol type="1">
<li><strong>Extract</strong> each respondent’s choice data and corresponding design matrix.</li>
<li><strong>Estimate individual-level β vectors</strong> that vary across respondents.</li>
<li>Use <strong>Gibbs sampling</strong> to alternate between:
<ul>
<li>Sampling <strong>individual-level coefficients</strong> ((_i))<br>
</li>
<li>Sampling <strong>population-level parameters</strong> — the mean vector (()) and covariance matrix (())</li>
</ul></li>
</ol>
<p>This <strong>Hierarchical Bayesian (HB)</strong> approach allows us to: - Capture <strong>both market-level trends</strong> and <strong>individual-level variation</strong> - Generate richer, more accurate predictions - Offer deeper insights into <strong>preference heterogeneity</strong> across consumers</p>
<div id="7c1c60ca" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.linalg <span class="im">import</span> inv, cholesky</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> invwishart, multivariate_normal</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co"># individual level data</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>n_respondents <span class="op">=</span> <span class="bu">int</span>(mnl_prep_data[<span class="st">'id'</span>].<span class="bu">max</span>())</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>K <span class="op">=</span> mnl_prep_data[<span class="st">'X'</span>].shape[<span class="dv">1</span>]</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Group design matrix and choices by respondent</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>X_groups <span class="op">=</span> [mnl_prep_data[<span class="st">'X'</span>][mnl_prep_data[<span class="st">'id'</span>] <span class="op">==</span> i] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_respondents<span class="op">+</span><span class="dv">1</span>)]</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>y_groups <span class="op">=</span> [mnl_prep_data[<span class="st">'y'</span>][mnl_prep_data[<span class="st">'id'</span>] <span class="op">==</span> i] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_respondents<span class="op">+</span><span class="dv">1</span>)]</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>task_groups <span class="op">=</span> [mnl_prep_data[<span class="st">'task'</span>][mnl_prep_data[<span class="st">'id'</span>] <span class="op">==</span> i] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_respondents<span class="op">+</span><span class="dv">1</span>)]</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Hierarchical Priors</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>mu_0 <span class="op">=</span> np.zeros(K)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>Sigma_0 <span class="op">=</span> np.eye(K) <span class="op">*</span> <span class="dv">10</span>  <span class="co"># prior on mu</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> K <span class="op">+</span> <span class="dv">2</span>  <span class="co"># degrees of freedom for inverse-Wishart</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>scale_matrix <span class="op">=</span> np.eye(K)  <span class="co"># scale matrix for Sigma prior</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize</span></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> np.zeros(K)</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>Sigma <span class="op">=</span> np.eye(K)</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>beta_i <span class="op">=</span> np.random.randn(n_respondents, K)</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Storage</span></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>draws_mu <span class="op">=</span> []</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>draws_Sigma <span class="op">=</span> []</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper: Individual Log-likelihood</span></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> individual_log_likelihood(beta, X, y, task_ids):</span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.DataFrame({<span class="st">'util'</span>: X <span class="op">@</span> beta, <span class="st">'choice'</span>: y, <span class="st">'task'</span>: task_ids})</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'log_denom'</span>] <span class="op">=</span> df.groupby(<span class="st">'task'</span>)[<span class="st">'util'</span>].transform(<span class="kw">lambda</span> u: np.log(np.<span class="bu">sum</span>(np.exp(u))))</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'log_prob'</span>] <span class="op">=</span> df[<span class="st">'choice'</span>] <span class="op">*</span> (df[<span class="st">'util'</span>] <span class="op">-</span> df[<span class="st">'log_denom'</span>])</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df[<span class="st">'log_prob'</span>].<span class="bu">sum</span>()</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Gibbs Sampling</span></span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>n_iter <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> <span class="bu">iter</span> <span class="kw">in</span> <span class="bu">range</span>(n_iter):</span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 1: Update beta_i for each respondent</span></span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_respondents):</span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>        X_i <span class="op">=</span> X_groups[i]</span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>        y_i <span class="op">=</span> y_groups[i]</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>        task_i <span class="op">=</span> task_groups[i]</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>        curr_beta <span class="op">=</span> beta_i[i]</span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Metropolis step (local proposal)</span></span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a>        prop_beta <span class="op">=</span> curr_beta <span class="op">+</span> np.random.normal(scale<span class="op">=</span><span class="fl">0.1</span>, size<span class="op">=</span>K)</span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a>        ll_curr <span class="op">=</span> individual_log_likelihood(curr_beta, X_i, y_i, task_i)</span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a>        ll_prop <span class="op">=</span> individual_log_likelihood(prop_beta, X_i, y_i, task_i)</span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a>        prior_curr <span class="op">=</span> multivariate_normal.logpdf(curr_beta, mean<span class="op">=</span>mu, cov<span class="op">=</span>Sigma)</span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a>        prior_prop <span class="op">=</span> multivariate_normal.logpdf(prop_beta, mean<span class="op">=</span>mu, cov<span class="op">=</span>Sigma)</span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a>        log_accept_ratio <span class="op">=</span> (ll_prop <span class="op">+</span> prior_prop) <span class="op">-</span> (ll_curr <span class="op">+</span> prior_curr)</span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.log(np.random.rand()) <span class="op">&lt;</span> log_accept_ratio:</span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a>            beta_i[i] <span class="op">=</span> prop_beta</span>
<span id="cb19-58"><a href="#cb19-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-59"><a href="#cb19-59" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 2: Update mu | beta_i, Sigma</span></span>
<span id="cb19-60"><a href="#cb19-60" aria-hidden="true" tabindex="-1"></a>    beta_bar <span class="op">=</span> beta_i.mean(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb19-61"><a href="#cb19-61" aria-hidden="true" tabindex="-1"></a>    mu_cov <span class="op">=</span> inv(inv(Sigma_0) <span class="op">+</span> n_respondents <span class="op">*</span> inv(Sigma))</span>
<span id="cb19-62"><a href="#cb19-62" aria-hidden="true" tabindex="-1"></a>    mu_mean <span class="op">=</span> mu_cov <span class="op">@</span> (inv(Sigma_0) <span class="op">@</span> mu_0 <span class="op">+</span> n_respondents <span class="op">*</span> inv(Sigma) <span class="op">@</span> beta_bar)</span>
<span id="cb19-63"><a href="#cb19-63" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> np.random.multivariate_normal(mu_mean, mu_cov)</span>
<span id="cb19-64"><a href="#cb19-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-65"><a href="#cb19-65" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Step 3: Update Sigma | beta_i, mu</span></span>
<span id="cb19-66"><a href="#cb19-66" aria-hidden="true" tabindex="-1"></a>    S <span class="op">=</span> np.cov((beta_i <span class="op">-</span> mu).T, bias<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-67"><a href="#cb19-67" aria-hidden="true" tabindex="-1"></a>    Sigma <span class="op">=</span> invwishart.rvs(df<span class="op">=</span>df <span class="op">+</span> n_respondents, scale<span class="op">=</span>scale_matrix <span class="op">+</span> n_respondents <span class="op">*</span> S)</span>
<span id="cb19-68"><a href="#cb19-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-69"><a href="#cb19-69" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Store draws</span></span>
<span id="cb19-70"><a href="#cb19-70" aria-hidden="true" tabindex="-1"></a>    draws_mu.append(mu)</span>
<span id="cb19-71"><a href="#cb19-71" aria-hidden="true" tabindex="-1"></a>    draws_Sigma.append(Sigma)</span>
<span id="cb19-72"><a href="#cb19-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-73"><a href="#cb19-73" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="bu">iter</span> <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb19-74"><a href="#cb19-74" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Iteration </span><span class="sc">{</span><span class="bu">iter</span><span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> completed."</span>)</span>
<span id="cb19-75"><a href="#cb19-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-76"><a href="#cb19-76" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to DataFrames for summaries</span></span>
<span id="cb19-77"><a href="#cb19-77" aria-hidden="true" tabindex="-1"></a>draws_mu_df <span class="op">=</span> pd.DataFrame(draws_mu, columns<span class="op">=</span>[<span class="st">'beta_netflix'</span>, <span class="st">'beta_prime'</span>, <span class="st">'beta_ads'</span>, <span class="st">'beta_price'</span>])</span>
<span id="cb19-78"><a href="#cb19-78" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Posterior means for mu:"</span>)</span>
<span id="cb19-79"><a href="#cb19-79" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(draws_mu_df.mean())</span>
<span id="cb19-80"><a href="#cb19-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-81"><a href="#cb19-81" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Posterior standard deviations for mu:"</span>)</span>
<span id="cb19-82"><a href="#cb19-82" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(draws_mu_df.std())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Iteration 100 completed.
Iteration 200 completed.
Iteration 300 completed.
Iteration 400 completed.
Iteration 500 completed.
Iteration 600 completed.
Iteration 700 completed.
Iteration 800 completed.
Iteration 900 completed.
Iteration 1000 completed.

Posterior means for mu:
beta_netflix    0.636826
beta_prime      0.243485
beta_ads       -0.584385
beta_price     -0.112804
dtype: float64

Posterior standard deviations for mu:
beta_netflix    0.259804
beta_prime      0.095506
beta_ads        0.283320
beta_price      0.035660
dtype: float64</code></pre>
</div>
</div>
</section>
<section id="interpreting-output-from-the-hierarchical-bayesian-model" class="level3">
<h3 class="anchored" data-anchor-id="interpreting-output-from-the-hierarchical-bayesian-model">Interpreting Output from the Hierarchical Bayesian Model</h3>
<p>The output from the <strong>hierarchical Bayesian Multinomial Logit model</strong> summarizes the <strong>posterior distribution of the population-level means</strong> (()) for each parameter. These reflect the <strong>average preference weights</strong> across all individuals, while accounting for <strong>respondent-level heterogeneity</strong>.</p>
<hr>
<section id="β_prime" class="level4">
<h4 class="anchored" data-anchor-id="β_prime"><code>β_prime</code></h4>
<ul>
<li><strong>Posterior mean</strong>: 0.24<br>
</li>
<li>This is <strong>lower</strong> than the MLE (0.47) and flat-prior Bayesian estimate (0.48), highlighting the flexibility of the hierarchical model.</li>
<li>A <strong>standard deviation</strong> of 0.096 suggests moderate consensus among respondents — while <strong>preferences for Prime are generally positive</strong>, they are weaker and <strong>less varied</strong> compared to Netflix.</li>
</ul>
<hr>
</section>
<section id="β_ads" class="level4">
<h4 class="anchored" data-anchor-id="β_ads"><code>β_ads</code></h4>
<ul>
<li><strong>Posterior mean</strong>: –0.58<br>
</li>
<li>Still negative (as expected), but <strong>less extreme</strong> than the MLE/flat Bayesian estimates (≈ –0.77).</li>
<li>A <strong>larger standard deviation</strong> of 0.28 reveals greater <strong>heterogeneity</strong> in how respondents view ads.<br>
→ Some users are more tolerant of ads, while others strongly dislike them — this variation is captured by the hierarchical structure.</li>
</ul>
<hr>
</section>
<section id="β_price" class="level4">
<h4 class="anchored" data-anchor-id="β_price"><code>β_price</code></h4>
<ul>
<li><strong>Posterior mean</strong>: –0.11<br>
</li>
<li>Slightly <strong>more negative</strong> than the earlier estimates (≈ –0.096 to –0.097), suggesting <strong>greater overall price sensitivity</strong>.</li>
<li><strong>Standard deviation</strong>: 0.036<br>
→ Indicates relatively <strong>low variation</strong> — most respondents react <strong>similarly to price</strong>, even when individual preferences are allowed to vary.</li>
</ul>
<hr>
<p>These results demonstrate the <strong>value of hierarchical modeling</strong> in uncovering both <strong>average effects</strong> and <strong>individual-level diversity</strong>, enabling more nuanced insights than traditional models.</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>