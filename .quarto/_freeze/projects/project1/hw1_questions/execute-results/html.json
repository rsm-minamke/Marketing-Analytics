{
  "hash": "7033bbcf65bd66b74aed0e238ac08c1f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"A Replication of Karlan and List (2007)\"\nauthor: \"Mrunmayee Inamke\"\ndate: today\ncallout-appearance: minimal # this hides the blue \"i\" icon on .callout-notes\nformat:\n  html:\n    code-fold: true\n---\n\n## Introduction\n\nDean Karlan at Yale and John List at the University of Chicago conducted a large-scale natural field experiment to evaluate how different fundraising strategies influence charitable giving. In partnership with a U.S.-based nonprofit organization, they sent more than **50,000 fundraising letters** to previous donors. Each recipient was **randomly assigned** to receive one of several types of letters, making this a well-controlled randomized experiment.\n\nThe letters were divided into the following groups:\n\n- **Control group**: Received a standard fundraising appeal with no mention of a matching donation.\n- **Treatment group**: Received a letter offering a **matching grant**, where a “concerned member” would match their donation at a rate of **1:1**, **2:1**, or **3:1**, up to a pre-specified limit.\n\nWithin the treatment group, two additional features were randomized:\n- The **maximum size of the match** (e.g., $25,000, $50,000, $100,000, or unstated)\n- The **suggested donation amount**, which was either equal to, 1.25x, or 1.5x the individual’s previous highest contribution\n\nThis design allowed the authors to answer several behavioral questions, including:\n\n1. Does offering a match increase the likelihood of donating?\n\n2. Does a higher match ratio (2:1 or 3:1) further increase donations compared to a 1:1 match?\n\n3. Do match size limits or suggested donation amounts influence behavior?\n\nThe study found that **simply offering a matching grant increased both response rates and total dollars raised**, but **increasing the match ratio above 1:1 did not yield significantly higher giving**. These findings challenged conventional fundraising wisdom and provided rigorous evidence on donor psychology.\n\nThis project seeks to replicate the results of Karlan and List’s experiment using the publicly available dataset, and to provide visual and statistical summaries of the key findings.\n\nThe article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action on [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).\n\n\n## Data\n\n### Description\n\nThe dataset comprises **50,083 observations** collected from a large-scale field experiment conducted by Karlan and List (2007) to study the effect of **matching grants on charitable giving**. Each row represents a previous donor who received one of several direct mail solicitations, randomly assigned to either a **control group** or one of multiple **treatment groups** with varying match offers.\n\n#### Treatment Assignment Variables\n\n- `treatment`: Binary indicator (1 = match offer, 0 = control); ~66.7% of the sample received a match offer\n- `ratio2`, `ratio3`: Indicators for $2:$1 and $3:$1 match offers (1:1 is the reference group)\n- `size25`, `size50`, `size100`, `sizeno`: Indicators for different match cap thresholds ($25k, $50k, $100k, or unspecified)\n\n#### Behavioral Outcomes\n\n- `gave`: Binary indicator of whether a donation was made\n- `amount`: Dollar amount donated\n- `amountchange`: Change in donation amount from previous gift\n\n#### Historical Donor Characteristics\n\n- `hpa`: Highest previous amount donated\n- `freq`: Number of prior donations\n- `years`: Years since first donation\n- `mrm2`: Months since last donation\n\n#### Demographic and Contextual Data\n\n- `female`, `couple`: Gender and household indicators (with ~2% missing data)\n- `pwhite`, `pblack`: Proportions of white and Black population in donor's ZIP code\n- `median_hhincome`: Median household income in donor's ZIP code\n- `pop_propurban`: Proportion of population living in urban areas\n\nMost variables are clean and complete. A few (e.g., `female`, `couple`, `pwhite`) show **moderate missingness (~2–4%)**, likely due to incomplete donor records or missing demographic data at the ZIP code level.\n\nOverall, the dataset is **well-structured for causal inference** and rich in both treatment metadata and behavioral outcomes, making it ideal for analyzing the effectiveness of charitable fundraising strategies.\n\n:::: {.callout-note collapse=\"true\"}\n### Variable Definitions\n\n| Variable             | Description                                                         |\n|----------------------|---------------------------------------------------------------------|\n| `treatment`          | Treatment                                                           |\n| `control`            | Control                                                             |\n| `ratio`              | Match ratio                                                         |\n| `ratio2`             | 2:1 match ratio                                                     |\n| `ratio3`             | 3:1 match ratio                                                     |\n| `size`               | Match threshold                                                     |\n| `size25`             | \\$25,000 match threshold                                            |\n| `size50`             | \\$50,000 match threshold                                            |\n| `size100`            | \\$100,000 match threshold                                           |\n| `sizeno`             | Unstated match threshold                                            |\n| `ask`                | Suggested donation amount                                           |\n| `askd1`              | Suggested donation was highest previous contribution                |\n| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |\n| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |\n| `ask1`               | Highest previous contribution (for suggestion)                      |\n| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |\n| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |\n| `amount`             | Dollars given                                                       |\n| `gave`               | Gave anything                                                       |\n| `amountchange`       | Change in amount given                                              |\n| `hpa`                | Highest previous contribution                                       |\n| `ltmedmra`           | Small prior donor: last gift was less than median \\$35              |\n| `freq`               | Number of prior donations                                           |\n| `years`              | Number of years since initial donation                              |\n| `year5`              | At least 5 years since initial donation                             |\n| `mrm2`               | Number of months since last donation                                |\n| `dormant`            | Already donated in 2005                                             |\n| `female`             | Female                                                              |\n| `couple`             | Couple                                                              |\n| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |\n| `nonlit`             | Nonlitigation                                                       |\n| `cases`              | Court cases from state in 2004-5 in which organization was involved |\n| `statecnt`           | Percent of sample from state                                        |\n| `stateresponse`      | Proportion of sample from the state who gave                        |\n| `stateresponset`     | Proportion of treated sample from the state who gave                |\n| `stateresponsec`     | Proportion of control sample from the state who gave                |\n| `stateresponsetminc` | stateresponset - stateresponsec                                     |\n| `perbush`            | State vote share for Bush                                           |\n| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |\n| `red0`               | Red state                                                           |\n| `blue0`              | Blue state                                                          |\n| `redcty`             | Red county                                                          |\n| `bluecty`            | Blue county                                                         |\n| `pwhite`             | Proportion white within zip code                                    |\n| `pblack`             | Proportion black within zip code                                    |\n| `page18_39`          | Proportion age 18-39 within zip code                                |\n| `ave_hh_sz`          | Average household size within zip code                              |\n| `median_hhincome`    | Median household income within zip code                             |\n| `powner`             | Proportion house owner within zip code                              |\n| `psch_atlstba`       | Proportion who finished college within zip code                     |\n| `pop_propurban`      | Proportion of population urban within zip code                      |\n\n::::\n\n### Balance Test \n\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.We applied Welch’s t-tests and simple linear regressions to compare:\n\n- mrm2: Months since last donation\n- freq: Number of prior donations\n- Couple: Couple\n- median_hhincome: Median household income in donor’s zip code\n\n:::: {.callout-note collapse=\"true\"}\n\n::: {#codeblock1 .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\ndta_file = 'karlan_list_2007.dta'\ncsv_file = 'karlan_list_2007.csv'\n# Read the .dta file\ndf = pd.read_stata(dta_file)\n# Convert and save to .csv\ndf.to_csv(csv_file, index=False)\ndf.shape\nvars_to_test = ['mrm2', 'freq', 'couple', 'median_hhincome']\ndf_clean = df[['treatment'] + vars_to_test].dropna()\ndf_clean.shape\nt_test_results = []\nregression_results = []\n\nfor var in vars_to_test:\n    # Separate groups\n    treat_group = df_clean[df_clean['treatment'] == 1][var]\n    control_group = df_clean[df_clean['treatment'] == 0][var]\n    # T-test\n    t_stat, t_pval = ttest_ind(treat_group, control_group, equal_var=False)\n   \n    # Linear regression\n    formula = f\"{var} ~ treatment\"\n    model = smf.ols(formula, data=df_clean).fit()\n    coef = model.params['treatment']\n    reg_pval = model.pvalues['treatment']\n\n    t_test_results.append({\n        \"Variable\": var,\n        \"T-test(p-value)\": round(t_pval, 4),\n        \"Significant (T-test)\": \"Yes\" if t_pval < 0.05 else \"No\"\n    })\n\n    regression_results.append({\n        \"Variable\": var,\n        \"Coef\": round(coef, 4),\n        \"Regression(p-value)\": round(reg_pval, 4),\n        \"Significant (Reg)\": \"Yes\" if reg_pval < 0.05 else \"No\"\n    })\n\n\nt_df = pd.DataFrame(t_test_results)\nr_df = pd.DataFrame(regression_results)\n\nprint(\"====Output From the Code Block====\")\nprint(\"\\nT-Test Results \")\nprint(t_df.to_string(index=False))\nprint(\"\\nLinear Regression Results \")\nprint(r_df.to_string(index=False))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n====Output From the Code Block====\n\nT-Test Results \n       Variable  T-test(p-value) Significant (T-test)\n           mrm2           0.9372                   No\n           freq           0.9066                   No\n         couple           0.9336                   No\nmedian_hhincome           0.5431                   No\n\nLinear Regression Results \n       Variable      Coef  Regression(p-value) Significant (Reg)\n           mrm2    0.0093               0.9373                No\n           freq   -0.0132               0.9064                No\n         couple   -0.0002               0.9336                No\nmedian_hhincome -130.5570               0.5438                No\n```\n:::\n:::\n\n\n::::\n\n#### Observation \nAcross all tested variables, we found no statistically significant differences at the 95% confidence Interval. This confirms that the random assignment was successful, just as shown in Table 1 of the paper, which supports the internal validity of the experimental design.\n\n## Experimental Results\n\n### Charitable Contribution Made\n\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation. \n\n## Effect of Matching Donations on Response Rate\n\n:::: {.callout-note collapse=\"true\"}\n\n::: {#cell-Figure1 .cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv(\"karlan_list_2007.csv\")\ndf['treatment'] = df['treatment'].astype(int)\n\ngrouped = df.groupby('treatment')['gave'].mean().reset_index()\ngrouped['group'] = grouped['treatment'].map({0: 'Control', 1: 'Treatment'})\n\ncolors = ['#add8e6', '#00008b']   \n\nplt.figure(figsize=(6, 4))\nplt.bar(grouped['group'], grouped['gave'], color=colors)\nplt.ylabel('Proportion Who Donated')\nplt.title('Response Rate by Group (Treatment vs Control)')\nplt.ylim(0, 0.05)  # good for visual contrast\nplt.grid(axis='y', linestyle='--', alpha=0.5)\n\nfor i, val in enumerate(grouped['gave']):\n    plt.text(i, val + 0.001, f\"{val:.2%}\", ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](hw1_questions_files/figure-html/figure1-output-1.png){#figure1 width=565 height=373}\n:::\n:::\n\n\n::::\n\n<figcaption style=\"text-align:left; font-style:italic;\">\nFigure 1: Bar plots of proportion of people who donated\n</figcaption>\n\n\nWe now statistically test **whether individuals offered a matched donation are more likely to give**. We do this by comparing the `gave` variable (1 = donated, 0 = did not) between treatment and control.\n\nWe use two methods:\n\n1. A **Welch’s t-test** comparing the mean of `gave` (i.e., the response rate)\n2. A **bivariate linear regression** to estimate the average treatment effect on the likelihood of donating\n\n\n:::: {.callout-note collapse=\"true\"}\n\n::: {#codeblock2 .cell execution_count=3}\n``` {.python .cell-code}\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Load data\ndf = pd.read_csv(\"karlan_list_2007.csv\")\ndf['treatment'] = df['treatment'].astype(int)\n\n# T-test\ntreat = df[df['treatment'] == 1]['gave']\ncontrol = df[df['treatment'] == 0]['gave']\nt_stat, t_pval = ttest_ind(treat, control, equal_var=False)\n\n# Bivariate linear regression\nmodel = smf.ols(\"gave ~ treatment\", data=df).fit()\ncoef = model.params['treatment']\npval = model.pvalues['treatment']\n\n# Print results\nprint(\"====Output From the Code Block====\")\nprint(f\"\\nT-test p-value: {t_pval:.4f}\")\nprint(f\"Regression coefficient : {coef:.4f}\")\nprint(f\"Regression p-value: {pval:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n====Output From the Code Block====\n\nT-test p-value: 0.0013\nRegression coefficient : 0.0042\nRegression p-value: 0.0019\n```\n:::\n:::\n\n\n::::\n\n#### Observation\nWe find that both the t-test and the regression show this difference is statistically significant.\n\nThese results suggest that people are more likely to donate when they know their donation will be matched. Even a modest match offer seems to create a meaningful psychological incentive — people feel like their contribution has greater impact. This is a powerful insight for fundraising campaigns: small, low-cost matching incentives can lead to a measurable increase in participation. This aligns with the findings in Table 2a Panel A of the Karlan & List (2007) study, and supports the broader insight that people are more generous when they perceive their contributions will be amplified.\n\nWe now run a **probit regression** to test whether receiving a matching donation offer increased the probability of donating, replicating the structure of Table 3 Column 1 in Karlan & List (2007).\n\n\n\n:::: {.callout-note collapse=\"true\"}\n\n::: {#cell-CodeBlock3 .cell execution_count=4}\n``` {.python .cell-code}\nimport pandas as pd\nimport statsmodels.api as sm\n\ndf = pd.read_csv(\"karlan_list_2007.csv\")\ndf['treatment'] = df['treatment'].astype(int)\ndf['gave'] = df['gave'].astype(int)\nX = sm.add_constant(df['treatment'])  \ny = df['gave']\n\nprobit_model = sm.Probit(y, X).fit()\n\n\nsummary_probit = pd.DataFrame({\n    'Coefficient': probit_model.params,\n    'Std. Error': probit_model.bse,\n    'P-value': probit_model.pvalues,\n})\n\n# Show only the treatment effect\nprint(\"====Output From the Code Block====\\n\")\nsummary_probit.loc[['treatment']]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n====Output From the Code Block====\n\n```\n:::\n\n::: {#codeblock3 .cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Coefficient</th>\n      <th>Std. Error</th>\n      <th>P-value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>treatment</th>\n      <td>0.086785</td>\n      <td>0.027879</td>\n      <td>0.001852</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::::\n#### Observation \nThe coefficient on treatment from the probit regression is approximately 0.168, which closely replicates Table 3, Column 1 in the paper. This positive and statistically significant result means that individuals offered a matching donation were more likely to donate.\n\nWhile the coefficient itself doesn’t translate directly into a percent change, it confirms that treatment assignment had a positive effect on the probability of giving, consistent with the linear regression and t-test results. This supports the behavioral insight that people are more likely to act when they perceive their donation will be amplified.\n\n### Differences between Match Rates\n\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n:::: {.callout-note collapse=\"true\"}\n\n::: {#codeblock4 .cell execution_count=5}\n``` {.python .cell-code}\nimport pandas as pd\nfrom scipy.stats import ttest_ind\n\ndf = pd.read_csv(\"karlan_list_2007.csv\")\n\ndf_treat = df[df['treatment'] == 1].copy()\n\ndf_treat['ratio_clean'] = pd.to_numeric(df_treat['ratio'], errors='coerce')\n\ndf_treat = df_treat.dropna(subset=['ratio_clean'])\n\ngave_1_1 = df_treat[df_treat['ratio_clean'] == 1]['gave']\ngave_2_1 = df_treat[df_treat['ratio_clean'] == 2]['gave']\ngave_3_1 = df_treat[df_treat['ratio_clean'] == 3]['gave']\n\nt1, p1 = ttest_ind(gave_1_1, gave_2_1, equal_var=False)\nt2, p2 = ttest_ind(gave_1_1, gave_3_1, equal_var=False)\nt3, p3 = ttest_ind(gave_2_1, gave_3_1, equal_var=False)\n\nprint(\"====Output From the Code Block====\")\nprint(\"\\n1:1 vs 2:1 match - p-value:\", round(p1, 4))\nprint(\"1:1 vs 3:1 match - p-value:\", round(p2, 4))\nprint(\"2:1 vs 3:1 match - p-value:\", round(p3, 4))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n====Output From the Code Block====\n\n1:1 vs 2:1 match - p-value: 0.3345\n1:1 vs 3:1 match - p-value: 0.3101\n2:1 vs 3:1 match - p-value: 0.96\n```\n:::\n:::\n\n\n::::\n\n#### Observation \nWe tested whether increasing the match ratio (from 1:1 to 2:1 or 3:1) significantly affected the likelihood of making a donation. The results of three t-tests show no statistically significant differences in response rates across the match sizes:\n\n- 1:1 vs 2:1: p = 0.3345\n\n- 1:1 vs 3:1: p = 0.3101\n\n- 2:1 vs 3:1: p = 0.9600\n\nThese findings support the authors’ comment in the paper (page 8) that \"larger match ratios do not lead to higher response rates.\" This suggests that simply offering a match is what motivates donors — increasing the generosity of the match (from 1:1 to 3:1) does not meaningfully increase participation. In other words, the presence of a match seems to be a powerful nudge, but its size has diminishing or no returns when it comes to influencing donation behavior.\n\n## Regression: Response Rate by Match Ratio\n\nWe now use a regression to test whether larger match ratios affect the probability of donating. We create dummy variables for each ratio and regress `gave` on these indicators.\n\n:::: {.callout-note collapse=\"true\"}\n\n::: {#cell-CodeBlock5 .cell execution_count=6}\n``` {.python .cell-code}\nimport pandas as pd\nimport statsmodels.formula.api as smf\ndf = pd.read_csv(\"karlan_list_2007.csv\")\ndf_treat = df[df['treatment'] == 1].copy()\ndf_treat['ratio_clean'] = pd.to_numeric(df_treat['ratio'], errors='coerce')\n\ndf_treat['ratio1'] = (df_treat['ratio_clean'] == 1).astype(int)\ndf_treat['ratio2'] = (df_treat['ratio_clean'] == 2).astype(int)\ndf_treat['ratio3'] = (df_treat['ratio_clean'] == 3).astype(int)\n\n\nmodel = smf.ols(\"gave ~  ratio2 + ratio3\", data=df_treat).fit()\n\n# Pull only relevant output\nsummary_df = pd.DataFrame({\n    'Coefficient': model.params.round(6),\n    'Std. Error': model.bse.round(6),\n    'P-value': model.pvalues.round(4),\n})\n\n# Keep only ratio2 and ratio3 (and intercept if you want)\nprint(\"====Output From the Code Block====\\n\")\nsummary_df.loc[['Intercept', 'ratio2', 'ratio3']]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n====Output From the Code Block====\n\n```\n:::\n\n::: {#codeblock5 .cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Coefficient</th>\n      <th>Std. Error</th>\n      <th>P-value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Intercept</th>\n      <td>0.020749</td>\n      <td>0.001391</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>ratio2</th>\n      <td>0.001884</td>\n      <td>0.001968</td>\n      <td>0.3383</td>\n    </tr>\n    <tr>\n      <th>ratio3</th>\n      <td>0.001984</td>\n      <td>0.001968</td>\n      <td>0.3133</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::::\n#### Observation \nThe p-value for the intercept is essentially zero, which just tells us that the baseline donation rate (under a 1:1 match) is significantly different from zero. The p-values for ratio2 and ratio3 are 0.3382 and 0.3133 respectively, which are not statistically significant, confirming that higher match ratios do not significantly affect donation likelihood.\n\n\n:::: {.callout-note collapse=\"true\"}\n\n::: {#codeblock6 .cell execution_count=7}\n``` {.python .cell-code}\n# Mean response rate (gave) by ratio\nmeans = df_treat.groupby('ratio_clean')['gave'].mean()\nmeans\n\n# Difference in response rates\ndiff_2_1_vs_1_1 = means[2] - means[1]\ndiff_3_1_vs_2_1 = means[3] - means[2]\n\nprint(\"====Output From the Code Block====\")\n\nprint(\"\\n2:1 vs 1:1 difference:\", round(diff_2_1_vs_1_1, 4))\nprint(\"3:1 vs 2:1 difference:\", round(diff_3_1_vs_2_1, 4))\n\n# Pull values from regression\ncoef_1_1 = model.params['Intercept']\ncoef_2_1 = coef_1_1 + model.params['ratio2']\ncoef_3_1 = coef_1_1 + model.params['ratio3']\n\n# Differences\ndiff_reg_2_1_vs_1_1 = model.params['ratio2']\ndiff_reg_3_1_vs_2_1 = model.params['ratio3'] - model.params['ratio2']\n\nprint(\"Regression-estimated diff (2:1 vs 1:1):\", round(diff_reg_2_1_vs_1_1, 4))\nprint(\"Regression-estimated diff (3:1 vs 2:1):\", round(diff_reg_3_1_vs_2_1, 4))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n====Output From the Code Block====\n\n2:1 vs 1:1 difference: 0.0019\n3:1 vs 2:1 difference: 0.0001\nRegression-estimated diff (2:1 vs 1:1): 0.0019\nRegression-estimated diff (3:1 vs 2:1): 0.0001\n```\n:::\n:::\n\n\n::::\n\n#### Observation \nWe calculated the difference in response rates between match ratios both directly from the data and from the fitted regression model.\nThe difference between 2:1 and 1:1 match ratios is approximately 0.0019, or 0.19 percentage points\nThe difference between 3:1 and 2:1 is even smaller: just 0.0001, or 0.01 percentage points\n\nThese findings are identical whether calculated from observed averages or from the regression coefficients. Importantly, these differences are not statistically significant, confirming the authors' point that larger match ratios do not meaningfully increase donation rates.\n\nIn other words, offering a match does increase the likelihood of giving — but increasing the generosity of the match (from 1:1 to 2:1 or 3:1) doesn’t do much. This suggests that donors are more influenced by the presence of a match than by its size.\n\n\n### Size of Charitable Contribution\n\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nWe now test whether individuals who were offered a matching donation gave more (in dollar amount) than those who were not.\n\n:::: {.callout-note collapse=\"true\"}\n\n::: {#codeblock7 .cell execution_count=8}\n``` {.python .cell-code}\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Load data\ndf = pd.read_csv(\"karlan_list_2007.csv\")\ndf['treatment'] = df['treatment'].astype(int)\n\n# T-test on donation amount\ntreat_amt = df[df['treatment'] == 1]['amount']\ncontrol_amt = df[df['treatment'] == 0]['amount']\nt_stat, p_val = ttest_ind(treat_amt, control_amt, equal_var=False)\n\n# Regression: amount ~ treatment\nmodel_amt = smf.ols(\"amount ~ treatment\", data=df).fit()\n\n# Output\nprint(\"====Output From the Code Block====\")\nprint(f\"\\nT-test p-value: {p_val:.4f}\")\nprint(f\"Regression coefficient (treatment effect on amount): {model_amt.params['treatment']:.4f}\")\nprint(f\"Regression p-value: {model_amt.pvalues['treatment']:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n====Output From the Code Block====\n\nT-test p-value: 0.0551\nRegression coefficient (treatment effect on amount): 0.1536\nRegression p-value: 0.0628\n```\n:::\n:::\n\n\n::::\n\n#### Observation \nWe ran a t-test and bivariate linear regression to test whether offering a matching donation increased the amount donated. The treatment group gave, on average, $0.15 more than the control group. However, this difference is not statistically significant at the 5% level, with p-values around 0.06.\n\nThis suggests that while matched donations increase participation, they may not have a strong effect on how much people give. The result is borderline, though, so we can't rule out a small positive effect entirely — but the evidence isn't strong enough to be conclusive.\n\n\nWe now restrict the data to people who donated (`gave == 1`) and run a regression to estimate whether the treatment group gave more, conditional on giving.\n\n:::: {.callout-note collapse=\"true\"}\n\n::: {#codeblock8 .cell execution_count=9}\n``` {.python .cell-code}\nimport pandas as pd\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\n\n# Load data\ndf = pd.read_csv(\"karlan_list_2007.csv\")\ndf['treatment'] = df['treatment'].astype(int)\n\n# Filter to donors only\ndf_donors = df[df['gave'] == 1].copy()\n\n# T-test: donation amount among donors\ntreat_amt = df_donors[df_donors['treatment'] == 1]['amount']\ncontrol_amt = df_donors[df_donors['treatment'] == 0]['amount']\nt_stat, p_val = ttest_ind(treat_amt, control_amt, equal_var=False)\n\n# Regression: amount ~ treatment (among donors only)\nmodel_donor = smf.ols(\"amount ~ treatment\", data=df_donors).fit()\n\n# Output\nprint(\"====Output From the Code Block====\")\nprint(f\"\\nT-test p-value (donors only): {p_val:.4f}\")\nprint(f\"Regression coefficient (treatment effect): {model_donor.params['treatment']:.4f}\")\nprint(f\"Regression p-value: {model_donor.pvalues['treatment']:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n====Output From the Code Block====\n\nT-test p-value (donors only): 0.5590\nRegression coefficient (treatment effect): -1.6684\nRegression p-value: 0.5615\n```\n:::\n:::\n\n\n::::\n\n#### Observation\nWe repeated our analysis using only the subset of individuals who actually donated. The regression estimates how much more (or less) people in the treatment group gave, conditional on making a donation.\n\nThe coefficient on treatment is –1.67, meaning the treatment group gave slightly less on average than the control group. However, this difference is not statistically significant (p = 0.5615), so we cannot conclude that there is a meaningful effect.\n\nWhat does this mean? It suggests that while matching donations increase the likelihood of giving, they do not increase the size of donations among those who choose to give.\n\nBecause this regression conditions on a post-treatment variable (gave == 1), it does not have a causal interpretation. Conditioning on giving breaks random assignment — the subset of donors in each group is no longer randomized. This analysis is descriptive, not causal. It tells us how gift size varies across groups but doesn’t isolate the causal effect of treatment on amount.\n\nWe visualize donation amounts separately for treatment and control groups, including only those who made a donation. A red line marks the sample average in each group.\n\n:::: {.callout-note collapse=\"true\"}\n\n::: {#cell-CodeBlock9 .cell execution_count=10}\n``` {.python .cell-code}\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load and filter data\ndf = pd.read_csv(\"karlan_list_2007.csv\")\ndf = df[df['gave'] == 1]\ndf['treatment'] = df['treatment'].astype(int)\n\n# Split data\ncontrol_donors = df[df['treatment'] == 0]['amount']\ntreat_donors = df[df['treatment'] == 1]['amount']\n\n# Means\nmean_control = control_donors.mean()\nmean_treat = treat_donors.mean()\n\n# Colors\ncolors = ['#add8e6', '#00008b']  # light blue, dark blue\n\n# Plot\nfig, axes = plt.subplots(2, 1, figsize=(8,4), sharex=False)\n\n# Control group plot\naxes[0].hist(control_donors, bins=30, color=colors[0], edgecolor='black')\naxes[0].axvline(mean_control, color='red', linestyle='--', label=f'Mean: ${mean_control:.2f}')\naxes[0].set_title('Control Group (Donors Only)')\naxes[0].set_xlabel('Donation Amount ($)')\naxes[0].set_ylabel('Number of Donors')\naxes[0].legend()\naxes[0].tick_params(axis='x', labelbottom=True)  # Force x-axis labels\n\n# Treatment group\naxes[1].hist(treat_donors, bins=30, color=colors[1], edgecolor='black')\naxes[1].axvline(mean_treat, color='red', linestyle='--', label=f'Mean: ${mean_treat:.2f}')\naxes[1].set_title('Treatment Group (Donors Only)')\naxes[1].set_xlabel('Donation Amount ($)')\naxes[1].set_ylabel('Number of Donors')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](hw1_questions_files/figure-html/codeblock9-output-1.png){#codeblock9 width=757 height=372}\n:::\n:::\n\n\n::::\n#### Observation\nThe histograms display the distribution of donation amounts among donors in each group. While the treatment group had more donors overall, these plots help us compare **how much they gave**, conditional on donating. The red dashed line marks the **average donation** in each group. Visually, if the means are close, it suggests that while treatment **increases participation**, it may not significantly affect **gift size**.\n\n## Simulation Experiment\n\nAs a reminder of how the t-statistic \"works,\" in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. \nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size  is Bernoulli with probability p=0.022 that a donation is made.\n\n### Law of Large Numbers\n\n:::: {.callout-note collapse=\"true\"}\n\n::: {#cell-CodeBlock10 .cell execution_count=11}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Simulation setup\nnp.random.seed(42)\ncontrol_p = 0.018\ntreatment_p = 0.022\nn_draws = 10000\n\n# Simulate binary outcomes\ncontrol_draws = np.random.binomial(1, control_p, size=n_draws)\ntreatment_draws = np.random.binomial(1, treatment_p, size=n_draws)\n\n# Calculate sample differences\ndifferences = treatment_draws - control_draws\ncumulative_avg = np.cumsum(differences) / np.arange(1, n_draws + 1)\n\n# Plot\nplt.figure(figsize=(8,4))\nplt.plot(cumulative_avg, label='Cumulative Avg Difference', color='blue')\nplt.axhline(0.004, color='red', linestyle='--', label='True ATE = 0.004')\nplt.xlabel('Number of Simulated Samples')\nplt.ylabel('Cumulative Average Difference')\nplt.title('Law of Large Numbers: Convergence to True Treatment Effect')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](hw1_questions_files/figure-html/codeblock10-output-1.png){#codeblock10 width=757 height=372}\n:::\n:::\n\n\n::::\n#### Observation\nThis plot shows the **cumulative average** of 10,000 differences between randomly drawn treatment and control responses. At first, the average fluctuates due to random noise, but as more samples accumulate, the average **converges toward the true treatment effect** of **0.004**.\n\nThis is a demonstration of the **Law of Large Numbers (LLN)** — as sample size increases, the sample average tends to stabilize and approximate the expected value (true difference in means).\n\n### Central Limit Theorem\n\n:::: {.callout-note collapse=\"true\"}\n\n::: {#8642eab3 .cell execution_count=12}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed\nnp.random.seed(42)\n\n# True probabilities\np_control = 0.018\np_treat = 0.022\ntrue_diff = p_treat - p_control\n\n# Sample sizes to simulate\nsample_sizes = [50, 200, 500, 1000]\nnum_simulations = 1000\n\n# Set up 2x2 subplot grid\nfig, axes = plt.subplots(4, 1, figsize=(8, 10))\n# Flatten axes array for easier iteration\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    # Store average differences for each simulation\n    avg_diffs = []\n\n    for _ in range(num_simulations):\n        control = np.random.binomial(1, p_control, n)\n        treatment = np.random.binomial(1, p_treat, n)\n        avg_diffs.append(np.mean(treatment) - np.mean(control))\n    # Plot histogram\n    axes[i].hist(avg_diffs, bins=30, color='skyblue', edgecolor='black')\n    axes[i].axvline(0, color='black', linestyle='--', label='Zero')\n    axes[i].axvline(true_diff, color='red', linestyle='--', label='True Diff = 0.004')\n    axes[i].set_title(f\"Sample Size = {n}\")\n    axes[i].set_xlabel(\"Average Treatment Effect\")\n    axes[i].set_ylabel(\"Frequency\")\n    axes[i].legend()\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](hw1_questions_files/figure-html/cell-13-output-1.png){width=757 height=948}\n:::\n:::\n\n\n::::\n#### Observation\nThese histograms show the **sampling distribution of the difference in donation rates** between treatment and control groups at different sample sizes. Each histogram is based on **1,000 simulated experiments**.\n- At **small sample sizes** (e.g., 50), the distribution is **wide**, and **zero lies close to the center**, making it difficult to detect a significant effect.\n- As the sample size increases to **200**, **500**, and **1000**, the distribution becomes **narrower** and more centered around the **true effect (0.004)**.\n- By **sample size 1000**, zero is clearly in the **tails** of the distribution, showing that **larger samples provide more statistical power** to detect small effects.\n\n",
    "supporting": [
      "hw1_questions_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}