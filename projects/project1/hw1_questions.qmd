---
title: "A Replication of Karlan and List (2007)"
author: "Mrunmayee Inamke"
date: today
callout-appearance: minimal # this hides the blue "i" icon on .callout-notes
format:
  html:
    code-fold: true
---

## Introduction

Dean Karlan at Yale and John List at the University of Chicago conducted a large-scale natural field experiment to evaluate how different fundraising strategies influence charitable giving. In partnership with a U.S.-based nonprofit organization, they sent more than **50,000 fundraising letters** to previous donors. Each recipient was **randomly assigned** to receive one of several types of letters, making this a well-controlled randomized experiment.

The letters were divided into the following groups:

- **Control group**: Received a standard fundraising appeal with no mention of a matching donation.
- **Treatment group**: Received a letter offering a **matching grant**, where a “concerned member” would match their donation at a rate of **1:1**, **2:1**, or **3:1**, up to a pre-specified limit.

Within the treatment group, two additional features were randomized:
- The **maximum size of the match** (e.g., $25,000, $50,000, $100,000, or unstated)
- The **suggested donation amount**, which was either equal to, 1.25x, or 1.5x the individual’s previous highest contribution

This design allowed the authors to answer several behavioral questions, including:

1. Does offering a match increase the likelihood of donating?

2. Does a higher match ratio (2:1 or 3:1) further increase donations compared to a 1:1 match?

3. Do match size limits or suggested donation amounts influence behavior?

The study found that **simply offering a matching grant increased both response rates and total dollars raised**, but **increasing the match ratio above 1:1 did not yield significantly higher giving**. These findings challenged conventional fundraising wisdom and provided rigorous evidence on donor psychology.

This project seeks to replicate the results of Karlan and List’s experiment using the publicly available dataset, and to provide visual and statistical summaries of the key findings.

The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action on [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).


## Data

### Description

The dataset comprises **50,083 observations** collected from a large-scale field experiment conducted by Karlan and List (2007) to study the effect of **matching grants on charitable giving**. Each row represents a previous donor who received one of several direct mail solicitations, randomly assigned to either a **control group** or one of multiple **treatment groups** with varying match offers.

#### Treatment Assignment Variables

- `treatment`: Binary indicator (1 = match offer, 0 = control); ~66.7% of the sample received a match offer
- `ratio2`, `ratio3`: Indicators for $2:$1 and $3:$1 match offers (1:1 is the reference group)
- `size25`, `size50`, `size100`, `sizeno`: Indicators for different match cap thresholds ($25k, $50k, $100k, or unspecified)

#### Behavioral Outcomes

- `gave`: Binary indicator of whether a donation was made
- `amount`: Dollar amount donated
- `amountchange`: Change in donation amount from previous gift

#### Historical Donor Characteristics

- `hpa`: Highest previous amount donated
- `freq`: Number of prior donations
- `years`: Years since first donation
- `mrm2`: Months since last donation

#### Demographic and Contextual Data

- `female`, `couple`: Gender and household indicators (with ~2% missing data)
- `pwhite`, `pblack`: Proportions of white and Black population in donor's ZIP code
- `median_hhincome`: Median household income in donor's ZIP code
- `pop_propurban`: Proportion of population living in urban areas

Most variables are clean and complete. A few (e.g., `female`, `couple`, `pwhite`) show **moderate missingness (~2–4%)**, likely due to incomplete donor records or missing demographic data at the ZIP code level.

Overall, the dataset is **well-structured for causal inference** and rich in both treatment metadata and behavioral outcomes, making it ideal for analyzing the effectiveness of charitable fundraising strategies.

:::: {.callout-note collapse="true"}
### Variable Definitions

| Variable             | Description                                                         |
|----------------------|---------------------------------------------------------------------|
| `treatment`          | Treatment                                                           |
| `control`            | Control                                                             |
| `ratio`              | Match ratio                                                         |
| `ratio2`             | 2:1 match ratio                                                     |
| `ratio3`             | 3:1 match ratio                                                     |
| `size`               | Match threshold                                                     |
| `size25`             | \$25,000 match threshold                                            |
| `size50`             | \$50,000 match threshold                                            |
| `size100`            | \$100,000 match threshold                                           |
| `sizeno`             | Unstated match threshold                                            |
| `ask`                | Suggested donation amount                                           |
| `askd1`              | Suggested donation was highest previous contribution                |
| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |
| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |
| `ask1`               | Highest previous contribution (for suggestion)                      |
| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |
| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |
| `amount`             | Dollars given                                                       |
| `gave`               | Gave anything                                                       |
| `amountchange`       | Change in amount given                                              |
| `hpa`                | Highest previous contribution                                       |
| `ltmedmra`           | Small prior donor: last gift was less than median \$35              |
| `freq`               | Number of prior donations                                           |
| `years`              | Number of years since initial donation                              |
| `year5`              | At least 5 years since initial donation                             |
| `mrm2`               | Number of months since last donation                                |
| `dormant`            | Already donated in 2005                                             |
| `female`             | Female                                                              |
| `couple`             | Couple                                                              |
| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |
| `nonlit`             | Nonlitigation                                                       |
| `cases`              | Court cases from state in 2004-5 in which organization was involved |
| `statecnt`           | Percent of sample from state                                        |
| `stateresponse`      | Proportion of sample from the state who gave                        |
| `stateresponset`     | Proportion of treated sample from the state who gave                |
| `stateresponsec`     | Proportion of control sample from the state who gave                |
| `stateresponsetminc` | stateresponset - stateresponsec                                     |
| `perbush`            | State vote share for Bush                                           |
| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |
| `red0`               | Red state                                                           |
| `blue0`              | Blue state                                                          |
| `redcty`             | Red county                                                          |
| `bluecty`            | Blue county                                                         |
| `pwhite`             | Proportion white within zip code                                    |
| `pblack`             | Proportion black within zip code                                    |
| `page18_39`          | Proportion age 18-39 within zip code                                |
| `ave_hh_sz`          | Average household size within zip code                              |
| `median_hhincome`    | Median household income within zip code                             |
| `powner`             | Proportion house owner within zip code                              |
| `psch_atlstba`       | Proportion who finished college within zip code                     |
| `pop_propurban`      | Proportion of population urban within zip code                      |

::::

### Balance Test 

As an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.We applied Welch’s t-tests and simple linear regressions to compare:

- mrm2: Months since last donation
- freq: Number of prior donations
- Couple: Couple
- median_hhincome: Median household income in donor’s zip code

:::: {.callout-note collapse="true"}
```{python}
#| label: CodeBlock1
import pandas as pd
from scipy.stats import ttest_ind
import statsmodels.formula.api as smf

dta_file = 'karlan_list_2007.dta'
csv_file = 'karlan_list_2007.csv'
# Read the .dta file
kar_df = pd.read_stata(dta_file)
# Convert and save to .csv
kar_df.to_csv(csv_file, index=False)
kar_df.shape
vars_to_test = ['mrm2', 'freq', 'couple', 'median_hhincome']
kar_df_clean = kar_df[['treatment'] + vars_to_test].dropna()
kar_df_clean.shape
t_test_results = []
regression = []

for var in vars_to_test:
    # Separate groups
    treat_group = kar_df_clean[kar_df_clean['treatment'] == 1][var]
    control_group = kar_df_clean[kar_df_clean['treatment'] == 0][var]
    # T-test
    t_stat, t_pval = ttest_ind(treat_group, control_group, equal_var=False)
   
    # Linear regression
    formula = f"{var} ~ treatment"
    model = smf.ols(formula, data=kar_df_clean).fit()
    coef = model.params['treatment']
    reg_pval = model.pvalues['treatment']

    t_test_results.append({
        "Variable": var,
        "T-test(p-value)": round(t_pval, 4),
        "Significant (T-test)": "Yes" if t_pval < 0.05 else "No"
    })

    regression.append({
        "Variable": var,
        "Coef": round(coef, 4),
        "Regression(p-value)": round(reg_pval, 4),
        "Significant (Reg)": "Yes" if reg_pval < 0.05 else "No"
    })


t_df = pd.DataFrame(t_test_results)
r_df = pd.DataFrame(regression)

print("====Output From the Code Block====")
print("\nT-Test Results ")
print(t_df.to_string(index=False))
print("\nLinear Regression Results ")
print(r_df.to_string(index=False))
```
#### Observation 
Across all tested variables, we found no statistically significant differences at the 95% confidence Interval. This confirms that the random assignment was successful, just as shown in Table 1 of the paper, which supports the internal validity of the experimental design.

## Experimental Results

### Charitable Contribution Made

First, I analyze whether matched donations lead to an increased response rate of making a donation. 

## Effect of Matching Donations on Response Rate

:::: {.callout-note collapse="true"}
```{python}
#| label: Figure1
import pandas as pd
import matplotlib.pyplot as plt

treat_df = pd.read_csv("karlan_list_2007.csv")
treat_df['treatment'] = treat_df['treatment'].astype(int)

grouped = treat_df.groupby('treatment')['gave'].mean().reset_index()
grouped['group'] = grouped['treatment'].map({0: 'Control', 1: 'Treatment'})

colors = ['#add8e6', '#00008b']   

plt.figure(figsize=(6, 4))
plt.bar(grouped['group'], grouped['gave'], color=colors)
plt.ylabel('Proportion Who Donated')
plt.title('Response Rate by Group (Treatment vs Control)')
plt.ylim(0, 0.05)  # good for visual contrast
plt.grid(axis='y', linestyle='--', alpha=0.5)

for i, val in enumerate(grouped['gave']):
    plt.text(i, val + 0.001, f"{val:.2%}", ha='center', va='bottom')

plt.tight_layout()
plt.show()
```
::::

<figcaption style="text-align:left; font-style:italic;">
Figure 1: Bar plots of proportion of people who donated
</figcaption>


We now statistically test **whether individuals offered a matched donation are more likely to give**. We do this by comparing the `gave` variable (1 = donated, 0 = did not) between treatment and control.

We use two methods:

1. A **Welch’s t-test** comparing the mean of `gave` (i.e., the response rate)
2. A **bivariate linear regression** to estimate the average treatment effect on the likelihood of donating


:::: {.callout-note collapse="true"}
```{python}
#|label: CodeBlock2
import pandas as pd
from scipy.stats import ttest_ind
import statsmodels.formula.api as smf

# Load data
gave_df = pd.read_csv("karlan_list_2007.csv")
gave_df['treatment'] = gave_df['treatment'].astype(int)

# T-test
treat = gave_df[gave_df['treatment'] == 1]['gave']
control = gave_df[gave_df['treatment'] == 0]['gave']
t_stat, t_pval = ttest_ind(treat, control, equal_var=False)

# Bivariate linear regression
model = smf.ols("gave ~ treatment", data=gave_df).fit()
coef = model.params['treatment']
pval = model.pvalues['treatment']

# Print results
print("====Output From the Code Block====")
print(f"\nT-test p-value: {t_pval:.4f}")
print(f"Regression coefficient : {coef:.4f}")
print(f"Regression p-value: {pval:.4f}")
```
::::

#### Observation
We find that both the t-test and the regression show this difference is statistically significant.

These results suggest that people are more likely to donate when they know their donation will be matched. Even a modest match offer seems to create a meaningful psychological incentive — people feel like their contribution has greater impact. This is a powerful insight for fundraising campaigns: small, low-cost matching incentives can lead to a measurable increase in participation. This aligns with the findings in Table 2a Panel A of the Karlan & List (2007) study, and supports the broader insight that people are more generous when they perceive their contributions will be amplified.

We now run a **probit regression** to test whether receiving a matching donation offer increased the probability of donating, replicating the structure of Table 3 Column 1 in Karlan & List (2007).



:::: {.callout-note collapse="true"}
```{python}
#| label: CodeBlock3
import pandas as pd
import statsmodels.api as sm

reg_df = pd.read_csv("karlan_list_2007.csv")
reg_df['treatment'] = reg_df['treatment'].astype(int)
reg_df['gave'] = reg_df['gave'].astype(int)
X = sm.add_constant(reg_df['treatment'])  
y = reg_df['gave']

probit_model = sm.Probit(y, X).fit()

summary_probit = pd.DataFrame({
    'Coefficient': probit_model.params,
    'Std. Error': probit_model.bse,
    'P-value': probit_model.pvalues,
})

# Show only the treatment effect
print("====Output From the Code Block====\n")
summary_probit.loc[['treatment']]
```
::::
#### Observation 
The coefficient on treatment from the probit regression is approximately 0.168, which closely replicates Table 3, Column 1 in the paper. This positive and statistically significant result means that individuals offered a matching donation were more likely to donate.

While the coefficient itself doesn’t translate directly into a percent change, it confirms that treatment assignment had a positive effect on the probability of giving, consistent with the linear regression and t-test results. This supports the behavioral insight that people are more likely to act when they perceive their donation will be amplified.

### Differences between Match Rates

Next, I assess the effectiveness of different sizes of matched donations on the response rate.

:::: {.callout-note collapse="true"}
```{python}
#| label: CodeBlock4
import pandas as pd
from scipy.stats import ttest_ind

compare_df = pd.read_csv("karlan_list_2007.csv")

compare_df_treat = compare_df[compare_df['treatment'] == 1].copy()

compare_df_treat['ratio_clean'] = pd.to_numeric(compare_df_treat['ratio'], errors='coerce')

compare_df_treat = compare_df_treat.dropna(subset=['ratio_clean'])

gave_1_1 = compare_df_treat[compare_df_treat['ratio_clean'] == 1]['gave']
gave_2_1 = compare_df_treat[compare_df_treat['ratio_clean'] == 2]['gave']
gave_3_1 = compare_df_treat[compare_df_treat['ratio_clean'] == 3]['gave']

t1, p1 = ttest_ind(gave_1_1, gave_2_1, equal_var=False)
t2, p2 = ttest_ind(gave_1_1, gave_3_1, equal_var=False)
t3, p3 = ttest_ind(gave_2_1, gave_3_1, equal_var=False)

print("====Output From the Code Block====")
print("\n1:1 vs 2:1 match - p-value:", round(p1, 4))
print("1:1 vs 3:1 match - p-value:", round(p2, 4))
print("2:1 vs 3:1 match - p-value:", round(p3, 4))
```
::::

#### Observation 
We explored whether increasing the matching ratio for donations — from a baseline of 1:1 to higher ratios of 2:1 and 3:1 — would significantly influence the likelihood that individuals choose to donate. To investigate this, we conducted a series of t-tests comparing response rates across the different match levels. The analysis yielded the following p-values:

1:1 vs. 2:1: p = 0.3345

1:1 vs. 3:1: p = 0.3101

2:1 vs. 3:1: p = 0.9600

None of these comparisons produced statistically significant differences, suggesting that increasing the match ratio does not lead to a corresponding increase in donation response rates.

These findings align with the authors’ observation on page 8 of the study, where they note that "larger match ratios do not lead to higher response rates." In essence, while offering a match can serve as an effective behavioral nudge to encourage giving, escalating the generosity of the match—from doubling to tripling the donor’s contribution—appears to offer little to no additional persuasive power. This implies that the presence of a match itself is the critical factor in motivating donors, rather than the magnitude of the match. Thus, from a cost-efficiency standpoint, organizations might not gain much by offering higher match ratios beyond the standard 1:1.

## Regression: Response Rate by Match Ratio

We now use a regression to test whether larger match ratios affect the probability of donating. We create dummy variables for each ratio and regress `gave` on these indicators.

:::: {.callout-note collapse="true"}
```{python}
#| label: CodeBlock5
import pandas as pd
import statsmodels.formula.api as smf
match_df = pd.read_csv("karlan_list_2007.csv")
df_treat = match_df[match_df['treatment'] == 1].copy()
df_treat['ratio_clean'] = pd.to_numeric(df_treat['ratio'], errors='coerce')

df_treat['ratio1'] = (df_treat['ratio_clean'] == 1).astype(int)
df_treat['ratio2'] = (df_treat['ratio_clean'] == 2).astype(int)
df_treat['ratio3'] = (df_treat['ratio_clean'] == 3).astype(int)

model = smf.ols("gave ~  ratio2 + ratio3", data=df_treat).fit()

# Pull only relevant output
summary_df = pd.DataFrame({
    'Coefficient': model.params.round(6),
    'Std. Error': model.bse.round(6),
    'P-value': model.pvalues.round(4),
})

# Keep only ratio2 and ratio3 (and intercept if you want)
print("====Output From the Code Block====\n")
summary_df.loc[['Intercept', 'ratio2', 'ratio3']]
```
::::
#### Observation 
The p-value for the intercept is essentially zero, which just tells us that the baseline donation rate (under a 1:1 match) is significantly different from zero. The p-values for ratio2 and ratio3 are 0.3382 and 0.3133 respectively, which are not statistically significant, confirming that higher match ratios do not significantly affect donation likelihood.


:::: {.callout-note collapse="true"}
```{python}
#| label: CodeBlock6
# Mean response rate (gave) by ratio
means = df_treat.groupby('ratio_clean')['gave'].mean()
means

# Difference in response rates
diff_2_1_vs_1_1 = means[2] - means[1]
diff_3_1_vs_2_1 = means[3] - means[2]

print("====Output From the Code Block====")

print("\n2:1 vs 1:1 difference:", round(diff_2_1_vs_1_1, 4))
print("3:1 vs 2:1 difference:", round(diff_3_1_vs_2_1, 4))

# Pull values from regression
coef_1_1 = model.params['Intercept']
coef_2_1 = coef_1_1 + model.params['ratio2']
coef_3_1 = coef_1_1 + model.params['ratio3']

# Differences
diff_reg_2_1_vs_1_1 = model.params['ratio2']
diff_reg_3_1_vs_2_1 = model.params['ratio3'] - model.params['ratio2']

print("Regression-estimated diff (2:1 vs 1:1):", round(diff_reg_2_1_vs_1_1, 4))
print("Regression-estimated diff (3:1 vs 2:1):", round(diff_reg_3_1_vs_2_1, 4))
```
::::

#### Observation 
To better understand how varying match ratios influence donor behavior, we compared response rates using both raw data and estimates derived from a fitted regression model. The results were remarkably consistent across both methods.

The estimated difference in response rates between the 2:1 and 1:1 match ratios is approximately 0.0019, or 0.19 percentage points.

The difference between the 3:1 and 2:1 match ratios is even smaller — just 0.0001, or 0.01 percentage points.

These differences, though precisely calculated, are not statistically significant, reinforcing the conclusion that larger match ratios do not lead to meaningful increases in participation. Whether measured directly from the observed averages or inferred via regression coefficients, the effect size remains minimal.

This finding bolsters the claim made by the study’s authors that it is the presence of a match that matters, not its magnitude. In other words, once a match is offered — say, at a 1:1 level — increasing the match to 2:1 or 3:1 adds virtually no persuasive power. This has practical implications: organizations seeking to maximize participation may be better off using simple match offers rather than escalating the matching rate, which adds financial cost without commensurate gains in donor engagement.


### Size of Charitable Contribution

In addition to analyzing whether people are more likely to donate when offered a match, we also examined whether those who do choose to give contribute larger amounts when a match is present.

Specifically, we assess whether individuals exposed to a matching donation (regardless of its size) contribute more money compared to those who were not offered any match at all. This analysis focuses on the size of the charitable contribution as the dependent variable.

By isolating this behavioral dimension — not just the decision to give, but how much to give — we can gain deeper insight into whether matching gifts serve as an incentive to amplify generosity, even if they don't necessarily increase participation rates at higher ratios. Findings from this part of the analysis will shed light on the broader utility of match offers in charitable fundraising.

:::: {.callout-note collapse="true"}
```{python}
#| label: CodeBlock7
import pandas as pd
from scipy.stats import ttest_ind
import statsmodels.formula.api as smf

# Load data
size_df = pd.read_csv("karlan_list_2007.csv")
size_df['treatment'] = size_df['treatment'].astype(int)

# T-test on donation amount
treat_amt = size_df[size_df['treatment'] == 1]['amount']
control_amt = size_df[size_df['treatment'] == 0]['amount']
t_stat, p_val = ttest_ind(treat_amt, control_amt, equal_var=False)

# Regression: amount ~ treatment
model_amt = smf.ols("amount ~ treatment", data=size_df).fit()

# Output
print("====Output From the Code Block====")
print(f"\nT-test p-value: {p_val:.4f}")
print(f"Regression coefficient (treatment effect on amount): {model_amt.params['treatment']:.4f}")
print(f"Regression p-value: {model_amt.pvalues['treatment']:.4f}")
```
::::

#### Observation 
To assess whether offering a matching donation influences not just whether people donate, but also how much they give, we conducted both a t-test and a bivariate linear regression comparing donation amounts between the treatment and control groups.

The findings show that individuals in the treatment group — those offered a match — donated $0.15 more on average than those in the control group. However, this difference does not reach statistical significance at the conventional 5% threshold, with p-values hovering around 0.06.

While this result falls just short of statistical significance, it does suggest a possible trend. The effect size is small, and the p-value being close to 0.05 hints at a potential weak positive effect. Still, the current evidence is insufficient to draw definitive conclusions. In practical terms, this means that matching offers may slightly increase the donation amount, but this effect is subtle and not reliably distinguishable from random variation in this sample.

Thus, the results support a broader narrative: matching incentives appear to be more effective in motivating individuals to donate at all, rather than in substantially increasing the dollar amount given.

To gain further insight, we refine our analysis by focusing exclusively on individuals who did make a donation (gave == 1). This subset allows us to explore a different question: Among those who chose to donate, did the offer of a match lead them to contribute more money?

We run a regression within this restricted group to estimate the treatment effect conditional on giving. This approach helps isolate whether matching offers act as a lever to scale generosity among committed donors, as opposed to simply nudging non-donors into participation.

This follow-up analysis provides a more targeted view of donor behavior and may uncover subtle effects that are masked when looking at the entire sample, which includes a large proportion of non-donors. Results from this conditional regression will help clarify whether matching gifts amplify the intensity of giving among those already inclined to contribute.

:::: {.callout-note collapse="true"}
```{python}
#| label: CodeBlock8
import pandas as pd
from scipy.stats import ttest_ind
import statsmodels.formula.api as smf

# Load data
behave_df = pd.read_csv("karlan_list_2007.csv")
behave_df['treatment'] = behave_df['treatment'].astype(int)

# Filter to donors only
df_donors = behave_df[behave_df['gave'] == 1].copy()

# T-test: donation amount among donors
treat_amt = df_donors[df_donors['treatment'] == 1]['amount']
control_amt = df_donors[df_donors['treatment'] == 0]['amount']
t_stat, p_val = ttest_ind(treat_amt, control_amt, equal_var=False)

# Regression: amount ~ treatment (among donors only)
model_donor = smf.ols("amount ~ treatment", data=df_donors).fit()

# Output
print("====Output From the Code Block====")
print(f"\nT-test p-value (donors only): {p_val:.4f}")
print(f"Regression coefficient (treatment effect): {model_donor.params['treatment']:.4f}")
print(f"Regression p-value: {model_donor.pvalues['treatment']:.4f}")
```
::::

#### Observation
To assess whether matching offers affect how much people donate once they’ve decided to give, we restricted our analysis to individuals who actually donated (gave == 1). A linear regression estimating donation amounts showed a treatment effect of –1.67, meaning the treatment group gave slightly less than the control group. However, this difference is not statistically significant (p = 0.5615), suggesting no meaningful effect.

This indicates that while matching donations increase participation, they do not increase the amount donated among those who give.

Importantly, because this regression conditions on a post-treatment variable (giving), it breaks the original random assignment and cannot be interpreted causally. Instead, the results are descriptive — they show how average donation sizes differ across groups, but not due to treatment alone.

We also visualized donation amounts for treatment and control donors, marking each group’s average with a red line. The means are very similar, reinforcing the conclusion: match offers motivate people to donate, but don’t influence how much they give.

:::: {.callout-note collapse="true"}
```{python}
#| label: CodeBlock9
import pandas as pd
import matplotlib.pyplot as plt

# Load and filter data
donate_df = pd.read_csv("karlan_list_2007.csv")
donate_df = donate_df[donate_df['gave'] == 1]
donate_df['treatment'] = donate_df['treatment'].astype(int)

# Split data
control_donors = donate_df[donate_df['treatment'] == 0]['amount']
treat_donors = donate_df[donate_df['treatment'] == 1]['amount']

# Means
mean_control = control_donors.mean()
mean_treat = treat_donors.mean()

# Colors
colors = ['#add8e6', '#00008b']  # light blue, dark blue

# Plot
fig, axes = plt.subplots(2, 1, figsize=(8,4), sharex=False)

# Control group plot
axes[0].hist(control_donors, bins=30, color=colors[0], edgecolor='black')
axes[0].axvline(mean_control, color='red', linestyle='--', label=f'Mean: ${mean_control:.2f}')
axes[0].set_title('Control Group (Donors Only)')
axes[0].set_xlabel('Donation Amount ($)')
axes[0].set_ylabel('Number of Donors')
axes[0].legend()
axes[0].tick_params(axis='x', labelbottom=True)  # Force x-axis labels

# Treatment group
axes[1].hist(treat_donors, bins=30, color=colors[1], edgecolor='black')
axes[1].axvline(mean_treat, color='red', linestyle='--', label=f'Mean: ${mean_treat:.2f}')
axes[1].set_title('Treatment Group (Donors Only)')
axes[1].set_xlabel('Donation Amount ($)')
axes[1].set_ylabel('Number of Donors')
axes[1].legend()

plt.tight_layout()
plt.show()
```
::::
#### Observation
Visualizing Donation Amounts
The histograms illustrate the distribution of donation amounts among those who gave, separated by treatment and control groups. While the treatment group included more donors overall, these plots focus on how much each group gave, conditional on donating. The red dashed line represents the average donation in each group. When the means appear similar, it reinforces the idea that although the treatment boosts donation rates, it does not significantly impact gift size among those who donate.

Simulation Experiment
To reinforce how the t-statistic behaves, we run a simulation demonstrating the Law of Large Numbers and the Central Limit Theorem.

Assume:

For the control group (no match), donations follow a Bernoulli distribution with p = 0.018.

For the treatment group (any match), donations follow a Bernoulli distribution with p = 0.022.

This setup lets us explore how sampling variability affects the t-statistic and how, with larger samples, the estimated differences converge toward the true population values.

### Law of Large Numbers

:::: {.callout-note collapse="true"}
```{python}
#| label: CodeBlock10
import numpy as np
import matplotlib.pyplot as plt

# Simulation setup
np.random.seed(42)
control_p = 0.018
treatment_p = 0.022
n_draws = 10000

# Simulate binary outcomes
control_draws = np.random.binomial(1, control_p, size=n_draws)
treatment_draws = np.random.binomial(1, treatment_p, size=n_draws)

# Calculate sample differences
differences = treatment_draws - control_draws
cumulative_avg = np.cumsum(differences) / np.arange(1, n_draws + 1)

# Plot
plt.figure(figsize=(8,4))
plt.plot(cumulative_avg, label='Cumulative Avg Difference', color='blue')
plt.axhline(0.004, color='red', linestyle='--', label='True ATE = 0.004')
plt.xlabel('Number of Simulated Samples')
plt.ylabel('Cumulative Average Difference')
plt.title('Law of Large Numbers: Convergence to True Treatment Effect')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
```
::::
#### Observation
This plot displays the cumulative average of 10,000 simulated differences between randomly sampled treatment and control responses. Initially, the average varies due to random noise, but as more samples are added, it gradually stabilizes around the true treatment effect of 0.004.

This illustrates the Law of Large Numbers (LLN): as the sample size grows, the sample average converges to the true population mean, reflecting the expected difference between groups.
### Central Limit Theorem

:::: {.callout-note collapse="true"}
```{python}
import numpy as np
import matplotlib.pyplot as plt

# Set seed
np.random.seed(42)

# True probabilities
p_control = 0.018
p_treat = 0.022
true_diff = p_treat - p_control

# Sample sizes to simulate
sample_sizes = [50, 200, 500, 1000]
num_simulations = 1000

# Set up 2x2 subplot grid
fig, axes = plt.subplots(4, 1, figsize=(8, 10))
# Flatten axes array for easier iteration
axes = axes.flatten()

for i, n in enumerate(sample_sizes):
    # Store average differences for each simulation
    avg_diffs = []

    for _ in range(num_simulations):
        control = np.random.binomial(1, p_control, n)
        treatment = np.random.binomial(1, p_treat, n)
        avg_diffs.append(np.mean(treatment) - np.mean(control))
    # Plot histogram
    axes[i].hist(avg_diffs, bins=30, color='skyblue', edgecolor='black')
    axes[i].axvline(0, color='black', linestyle='--', label='Zero')
    axes[i].axvline(true_diff, color='red', linestyle='--', label='True Diff = 0.004')
    axes[i].set_title(f"Sample Size = {n}")
    axes[i].set_xlabel("Average Treatment Effect")
    axes[i].set_ylabel("Frequency")
    axes[i].legend()
plt.tight_layout()
plt.show()
```
::::
#### Observation
These histograms show the **sampling distribution of the difference in donation rates** between treatment and control groups at different sample sizes. Each histogram is based on **1,000 simulated experiments**.
- At **small sample sizes** (e.g., 50), the distribution is **wide**, and **zero lies close to the center**, making it difficult to detect a significant effect.
- As the sample size increases to **200**, **500**, and **1000**, the distribution becomes **narrower** and more centered around the **true effect (0.004)**.
- By **sample size 1000**, zero is clearly in the **tails** of the distribution, showing that **larger samples provide more statistical power** to detect small effects.






